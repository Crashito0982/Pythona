# === CONSOLIDADO PROSEGUR UNIFICADO ===
import os
import re
import shutil
import unicodedata
from datetime import datetime
from pathlib import Path
from typing import Optional, Union, List, Dict, Any, Tuple

import numpy as np
import pandas as pd

from loguru import logger
import sys

# =========================================================
# CONFIGURACI√ìN DE RUTAS (LOCAL vs PRODUCCI√ìN)
# =========================================================

MODO = "LOCAL"      # Cambiar a "PROD" en Airflow

if MODO == "LOCAL":
    # Ruta local (Jupyter)
    root_path = Path("/home/leonardd/Plexus/PROSEGUR") # o la ruta que se use prueba para el procesamiento.
elif MODO == "PROD":
    # Ruta real en Airflow
    root_path = Path(r"//nfs_airflow_py/cmdat/ea-saa-datos/Transportadoras/Prosegur")
else:
    raise ValueError(f"MODO desconocido: {MODO}")

# Configuraci√≥n b√°sica del logger
logger.remove()
logger.add(sys.stdout, level="INFO", format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}")

# Agencias esperadas como subcarpetas dentro del ROOT (carpeta PROSEGUR)
AGENCIAS = ['ASU', 'CDE', 'CNC', 'ENC', 'OVD']

def _strip_accents(s: str) -> str:
    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')


def _first_non_empty_after(row_vals: List[str], start_idx: int) -> Optional[int]:
    """Devuelve el √≠ndice de la primera celda no vac√≠a a partir de start_idx+1, o None."""
    for i in range(start_idx + 1, len(row_vals)):
        if str(row_vals[i]).strip() != '':
            return i
    return None


def _get_cell(row_vals: List[str], idx: Optional[int], default: str = '') -> str:
    if idx is None or idx >= len(row_vals):
        return default
    v = str(row_vals[idx]).strip()
    return v if v != '' else default


def _only_digits(s: str) -> str:
    """Devuelve solo d√≠gitos (para recibo), sin cortar ceros a la izquierda."""
    return ''.join(ch for ch in str(s) if ch.isdigit())


def _ordenar_y_renombrar_columnas_ec(df: pd.DataFrame) -> pd.DataFrame:
    """Normaliza encabezados y asegura el orden final esperado para EC_*."""
    df.columns = [str(c).replace(' ', '_').upper() for c in df.columns]
    rename_map = {'FECHA_OPER': 'FECHA', 'MOTIVO MOVIMIENTO': 'MOTIVO_MOVIMIENTO'}
    df = df.rename(columns=rename_map)
    orden_final = [
        'FECHA',
        'SUCURSAL',
        'RECIBO',
        'BULTOS',
        'GUARANIES',
        'DOLARES',
        'ING_EGR',
        'CLASIFICACION',
        'FECHA_ARCHIVO',
        'MOTIVO_MOVIMIENTO',
        'AGENCIA',
        'SALDO_ANTERIOR_PYG',
        'SALDO_ANTERIOR_USD',
    ]
    for col in orden_final:
        if col not in df.columns:
            # Para saldos, por defecto 0; para el resto, cadena vac√≠a
            if col.startswith('SALDO_ANTERIOR'):
                df[col] = 0
            else:
                df[col] = ''
    return df[orden_final]

def _buscar_saldos_en_matriz(df: pd.DataFrame,
                             max_take: int = 4,
                             skip_first: int = 0) -> List[int]:
    """
    Busca la celda donde aparece 'SALDO ANTERIOR' (soportando celdas combinadas)
    en TODO el DataFrame y devuelve hasta max_take valores num√©ricos a la derecha
    y en las filas inmediatamente de abajo.

    - max_take   = cantidad de n√∫meros que queremos recuperar
    - skip_first = cu√°ntos n√∫meros saltar al inicio (ej. para ignorar 'cantidad de bultos')
    """
    if df is None or df.empty:
        return []

    # Matriz de texto
    matriz = df.fillna("").astype(str).values
    nrows, ncols = matriz.shape

    ups = [[_strip_accents(str(c)).upper() for c in fila] for fila in matriz]

    fila_base = None
    col_base = None

    # 1) Buscar "SALDO ANTERIOR" en una sola celda
    for i in range(nrows):
        for j in range(ncols):
            if "SALDO ANTERIOR" in ups[i][j]:
                fila_base, col_base = i, j
                break
        if fila_base is not None:
            break

    # 2) Si no, "SALDO" + "ANTERIOR" en celdas contiguas
    if fila_base is None:
        for i in range(nrows):
            for j in range(ncols - 1):
                if "SALDO" in ups[i][j] and "ANTERIOR" in ups[i][j + 1]:
                    fila_base, col_base = i, j + 1
                    break
            if fila_base is not None:
                break

    # 3) Fallback: cualquier celda que mencione SALDO o ANTERIOR
    if fila_base is None:
        for i in range(nrows):
            for j in range(ncols):
                if "SALDO" in ups[i][j] or "ANTERIOR" in ups[i][j]:
                    fila_base, col_base = i, j
                    break
            if fila_base is not None:
                break

    if fila_base is None:
        return []

    # 4) Escanear a la derecha y unas filas abajo
    numeros: List[int] = []
    fila_limite = min(nrows, fila_base + 4)   # misma fila + hasta 3 filas abajo
    col_limite = min(ncols, col_base + 40)    # hasta 40 columnas a la derecha

    for i in range(fila_base, fila_limite):
        for j in range(col_base + 1, col_limite):
            # Si ya juntamos lo que necesitamos, cortamos
            if len(numeros) >= (max_take + skip_first):
                break
            txt = str(matriz[i][j]).strip()
            # Si la celda no tiene d√≠gitos, la ignoramos
            if not re.search(r"\d", txt):
                continue
            val = _to_int(txt)
            numeros.append(val)
        if len(numeros) >= (max_take + skip_first):
            break

    # Saltamos los primeros que no nos interesan (ej. cantidad de bultos)
    if skip_first:
        numeros = numeros[skip_first:]

    return numeros[:max_take]

def _extraer_saldos_en_df(df: pd.DataFrame, max_take: int = 6) -> List[int]:
    """
    Busca la celda donde aparece 'SALDO ANTERIOR' (soportando celdas combinadas)
    en todo el DataFrame y devuelve hasta max_take valores num√©ricos que est√©n
    a la derecha y/o en las filas inmediatas inferiores.
    """
    if df is None or df.empty:
        return []

    # matriz de texto
    valores = df.fillna("").astype(str).values
    nrows, ncols = valores.shape

    ups = [[_strip_accents(str(v)).upper() for v in row] for row in valores]

    fila_base = None
    col_base = None

    # 1) "SALDO ANTERIOR" en una sola celda
    for i in range(nrows):
        for j in range(ncols):
            u = ups[i][j]
            if "SALDO ANTERIOR" in u:
                fila_base, col_base = i, j
                break
        if fila_base is not None:
            break

    # 2) "SALDO" + "ANTERIOR" en celdas contiguas
    if fila_base is None:
        for i in range(nrows):
            for j in range(ncols - 1):
                u1 = ups[i][j]
                u2 = ups[i][j + 1]
                if "SALDO" in u1 and "ANTERIOR" in u2:
                    fila_base, col_base = i, j + 1
                    break
            if fila_base is not None:
                break

    # 3) Fallback: cualquier celda que mencione SALDO o ANTERIOR
    if fila_base is None:
        for i in range(nrows):
            for j in range(ncols):
                u = ups[i][j]
                if "SALDO" in u or "ANTERIOR" in u:
                    fila_base, col_base = i, j
                    break
            if fila_base is not None:
                break

    if fila_base is None:
        return []

    # 4) Escanear hacia la derecha y un par de filas abajo
    resultado: List[int] = []
    fila_limite = min(nrows, fila_base + 4)  # misma fila + hasta 3 filas debajo

    for i in range(fila_base, fila_limite):
        for j in range(col_base + 1, ncols):
            if len(resultado) >= max_take:
                break
            txt = str(valores[i][j]).strip()
            if not txt:
                continue
            n = _to_int(txt)  # esta _to_int devuelve None si no es n√∫mero
            if n is None:
                continue
            resultado.append(n)
        if len(resultado) >= max_take:
            break

    return resultado

def encontrar_fecha(texto: str) -> Optional[str]:
    """Encuentra dd/mm/yyyy en un texto; devuelve la primera coincidencia o None."""
    if not texto:
        return None
    m = re.search(r'(\d{1,2}/\d{1,2}/\d{4})', texto)
    return m.group(1) if m else None


def encontrar_fecha_en_columna(serie: pd.Series) -> Optional[str]:
    """Busca la primera fecha v√°lida dd/mm/yyyy en una serie/columna libre."""
    for val in serie.astype(str).tolist():
        f = encontrar_fecha(val)
        if f:
            return f
    return None


def get_agencia(linea_cabecera: str) -> str:
    """
    Extrae la agencia de una l√≠nea tipo 'PROSEGUR PARAGUAY S.A. (SUCURSAL: Ciudad del Este)'.
    Si no encuentra, devuelve ''.
    """
    if not linea_cabecera:
        return ''
    m = re.search(r'SUCURSAL:\s*([^)]+)\)', linea_cabecera, flags=re.IGNORECASE)
    return m.group(1).strip() if m else ''


def _normaliza_moneda(token: str) -> str:
    """Normaliza a: GUARANIES, DOLARES, EUROS, REALES, PESOS."""
    t = _strip_accents(str(token)).upper()
    if 'GUARANI' in t:
        return 'GUARANIES'
    if 'DOLAR' in t or 'DOLARE' in t or 'USD' in t:
        return 'DOLARES'
    if 'EURO' in t or 'EUR' in t:
        return 'EUROS'
    if 'REAL' in t or 'BRL' in t:
        return 'REALES'
    if 'PESO' in t or 'ARS' in t:
        return 'PESOS'
    return t

def _normaliza_moneda_iso(token: str) -> str:
    t = _strip_accents(str(token)).upper().strip()
    if any(k in t for k in ['PYG', 'GS', 'G$', '‚Ç≤', 'GUARANI']):
        return 'PYG'
    if any(k in t for k in ['USD', 'US$', 'U$S', 'DOLAR', 'DOLARES']):
        return 'USD'
    if any(k in t for k in ['EUR', '‚Ç¨', 'EURO']):
        return 'EUR'
    if any(k in t for k in ['BRL', 'R$', 'REAL']):
        return 'BRL'
    if any(k in t for k in ['ARS', 'PESO']):
        return 'ARS'
    return t

def _normaliza_agencia(s: str) -> str:
    t = _strip_accents(str(s)).upper().strip()

    # Ciudad del Este
    if 'CIUDAD DEL ESTE' in t or t == 'CDE':
        return 'CDE'
    # Asunci√≥n
    if 'ASUNCION' in t or t == 'ASU':
        return 'ASU'
    # Concepci√≥n  -> CON  (aceptamos CON, CNC y el nombre)
    if 'CONCEPCION' in t or t in {'CON', 'CNC'}:
        return 'CON'
    # Encarnaci√≥n
    if 'ENCARNACION' in t or t == 'ENC':
        return 'ENC'
    # Coronel Oviedo
    if 'OVIEDO' in t or t == 'OVD':
        return 'OVD'
    # Si no matchea, devolvemos algo corto y estable
    return t if len(t) <= 5 else t[:3]

def _guess_currency_from_sheet_name(sheet_name: str) -> str:
    """Intenta inferir la moneda a partir del nombre de la hoja."""
    n = _strip_accents(str(sheet_name)).upper()
    if any(k in n for k in ['USD', 'DOLAR', 'DOLARES']):
        return 'DOLARES'
    if any(k in n for k in ['EUR', 'EURO', 'EUROS']):
        return 'EUROS'
    if any(k in n for k in ['BRL', 'REAL', 'REALES']):
        return 'REALES'
    if any(k in n for k in ['ARS', 'PESO', 'PESOS', 'ARG']):
        return 'PESOS'
    if any(k in n for k in ['PYG', 'GUARANI']):
        return 'GUARANIES'
    return ''  # desconocido


def _leer_hojas_excel(path_entrada: str, sheet_name=None) -> dict:
    """
    Devuelve un dict {nombre_hoja: DataFrame} seg√∫n el par√°metro.
    None -> todas las hojas; int/str -> una sola; lista -> solo esas.
    """
    if sheet_name is None:
        return pd.read_excel(path_entrada, sheet_name=None, header=None, dtype=str)
    if isinstance(sheet_name, (list, tuple)):
        return pd.read_excel(path_entrada, sheet_name=list(sheet_name), header=None, dtype=str)
    # un solo nombre/√≠ndice
    df = pd.read_excel(path_entrada, sheet_name=sheet_name, header=None, dtype=str)
    return {sheet_name: df}


def _ordenar_y_renombrar_columnas_ec_banco(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).replace(' ', '_').upper() for c in df.columns]
    df = df.rename(columns={
        'FECHA_OPER': 'FECHA',
        'MONTO': 'IMPORTE',
        'MOTIVO MOVIMIENTO': 'MOTIVO_MOVIMIENTO',
    })
    orden_final = [
        'FECHA', 'SUCURSAL', 'RECIBO', 'BULTOS', 'IMPORTE', 'MONEDA',
        'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
        'AGENCIA', 'SALDO_ANTERIOR'
    ]
    for col in orden_final:
        if col not in df.columns:
            df[col] = ''
    return df[orden_final]


def _is_zero_like(s: str) -> bool:
    """True si el string representa 0 (con o sin separadores)."""
    t = str(s).replace(',', '').replace('.', '').strip()
    return t == '' or t == '0'


def _ordenar_y_renombrar_columnas_bultos(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).replace(' ', '_').upper() for c in df.columns]
    df = df.rename(columns={'FECHA_OPER': 'FECHA'})
    orden_final = [
        'FECHA', 'SUCURSAL', 'RECIBO', 'BULTOS', 'MONEDA', 'IMPORTE',
        'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
        'AGENCIA', 'SALDO_ANTERIOR_PYG', 'SALDO_ANTERIOR_USD', 'SALDO_ANTERIOR', 'HOJA_ORIGEN'
    ]
    for col in orden_final:
        if col not in df.columns:
            df[col] = 0 if col.startswith('SALDO_ANTERIOR') else ''
    return df[orden_final]


def _ordenar_y_renombrar_columnas_bultos_bco(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).replace(' ', '_').upper() for c in df.columns]
    df = df.rename(columns={'FECHA_OPER': 'FECHA'})
    orden_final = [
        'FECHA', 'SUCURSAL', 'RECIBO', 'BULTOS', 'MONEDA', 'IMPORTE',
        'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
        'AGENCIA', 'SALDO_ANTERIOR'
    ]
    for col in orden_final:
        if col not in df.columns:
            df[col] = ''
    return df[orden_final]

def _normaliza_moneda_iso(token: str) -> str:
    """
    Devuelve c√≥digos ISO comunes: PYG, USD, EUR, BRL, ARS.
    Tolera variantes locales (Gs, U$S, US$, R$, ‚Ç¨, 'guaran√≠es', etc).
    """
    t = _strip_accents(str(token)).upper().strip()

    # Casos espec√≠ficos primero (evitar colisiones con '$')
    if any(k in t for k in ['PYG', 'GS', 'G$', 'G ', '‚Ç≤', 'GUARANI', 'GUARANIES']):
        return 'PYG'
    if any(k in t for k in ['USD', 'US$', 'U$S', 'DOLAR', 'DOLARES']):
        return 'USD'
    if any(k in t for k in ['EUR', '‚Ç¨', 'EURO', 'EUROS']):
        return 'EUR'
    if any(k in t for k in ['BRL', 'R$', 'REAL', 'REALES']):
        return 'BRL'
    if any(k in t for k in ['ARS', 'PESO', 'PESOS', 'ARG']):
        return 'ARS'

    # Heur√≠stica: si aparece '$' y no se detect√≥ arriba, preferimos USD
    if '$' in t:
        return 'USD'
    return t  # fallback (por si usan un c√≥digo no previsto)


def _txt(x) -> str:
    return "" if pd.isna(x) else str(x).strip()


def _upper(x) -> str:
    return re.sub(r"\s+", " ", _txt(x)).upper()


def _to_int(x) -> Optional[int]:
    """Convierte valores tipo '3.000', '3,000', '3000.0' a int. Devuelve None si no es n√∫mero."""
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return None
    if isinstance(x, (int, float)) and not isinstance(x, bool):
        try:
            return int(round(float(x)))
        except Exception:
            pass
    s = _txt(x).replace("\xa0", " ").strip()
    if s == "":
        return None
    if re.fullmatch(r"\d+\.\d+", s):
        return int(float(s))
    digits = re.sub(r"[^\d\-]", "", s)
    if digits in ("", "-", "--"):
        return None
    try:
        return int(digits)
    except Exception:
        return None
    
def _extraer_saldos_desde_fila(strip_cells: List[str], max_take: int = 6) -> List[int]:
    """
    Busca la celda que contiene 'SALDO ANTERIOR' (acentos/espacios tolerados)
    y devuelve hasta max_take valores num√©ricos no vac√≠os a su derecha, ya convertidos a int.
    """
    up = [_strip_accents(c).upper() for c in strip_cells]
    try:
        idx = next(i for i, c in enumerate(up) if 'SALDO ANTERIOR' in c)
    except StopIteration:
        return []

    out: List[int] = []
    j = idx + 1
    while j < len(strip_cells) and len(out) < max_take:
        v = str(strip_cells[j]).strip()
        if v != '':
            out.append(_to_int(v) or 0)
        j += 1
    return out

def get_ec_atm(fecha_ejecucion: datetime,
               filename: str,
               dir_entrada: str,
               dir_consolidado: str,
               sheet_name: Union[int, str] = 0) -> Optional[str]:
    """
    Procesa un archivo EC_ATM*.* desde dir_entrada y genera un Excel procesado en dir_consolidado.
    Devuelve la ruta de salida o None si no se obtuvieron registros.
    """
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    # Lectura cruda (sin encabezados) y normalizaci√≥n b√°sica
    df_raw = pd.read_excel(path_entrada, sheet_name=sheet_name, header=None, dtype=str).fillna('')

    saldo_ant_usd: Optional[int] = 0
    saldo_ant_pyg: Optional[int] = 0

        # Intentar leer SALDO ANTERIOR a nivel de archivo (soporta celdas combinadas)
    try:
        _saldos_arch = _extraer_saldos_en_df(df_raw, max_take=2)
        if _saldos_arch:
            if len(_saldos_arch) >= 1:
                saldo_ant_usd = _saldos_arch[0] or 0
            if len(_saldos_arch) >= 2:
                saldo_ant_pyg = _saldos_arch[1] or 0
    except Exception as e:
        logger.info(f"[EC_ATM] {filename}: no se pudo determinar SALDO ANTERIOR global ({e}).")

    rx_fecha_cell = re.compile(r'^\s*\d{1,2}/\d{1,2}/\d{4}\s*$')
    rx_totales = re.compile(r'\b(TOTAL|SUBTOTAL)\b', re.IGNORECASE)

    agencia = ''
    fecha_archivo = ''
    clasificacion = 'ATM'
    ing_egr = ''  # IN / OUT
    motivo_actual = ''

    registros: List[Dict[str, str]] = []

    for _, row in df_raw.iterrows():
        cells = [str(x) if x is not None else '' for x in row.values]
        strip_cells = [c.strip() for c in cells]
        line_join = ' '.join([c for c in strip_cells if c])
        if not line_join:
            continue

        upper_join = _strip_accents(line_join).upper()

        # Cabeceras / metadatos
        if 'PROSEGUR PARAGUAY S.A.' in upper_join:
            # e.g. "PROSEGUR PARAGUAY S.A. (SUCURSAL: Ciudad del Este)"
            ag = get_agencia(line_join)
            if ag:
                agencia = ag
            continue

        if 'ESTADO DE CUENTA DE' in upper_join:
            m_f = re.search(r'AL:\s*(\d{1,2}/\d{1,2}/\d{4})', line_join, flags=re.IGNORECASE)
            if m_f:
                fecha_archivo = m_f.group(1)
            continue

        if upper_join == 'INGRESOS':
            ing_egr = 'IN'
            motivo_actual = ''
            continue

        if upper_join == 'EGRESOS':
            ing_egr = 'OUT'
            motivo_actual = ''
            continue

        if 'INFORME DE PROCESOS' in upper_join:
            # fin del bloque √∫til
            break

        if rx_totales.search(line_join):
            # ignorar l√≠neas de totales/subtotales
            continue

        # Buscar fila de "Saldo Anterior" (1¬∫ USD, 2¬∫ PYG)
        if 'SALDO ANTERIOR' in upper_join and not (saldo_ant_usd or saldo_ant_pyg):
            valores = _extraer_saldos_desde_fila(strip_cells)
            # EC_ATM: primer valor = USD, segundo = PYG
            if len(valores) >= 1 and valores[0] is not None:
                saldo_ant_usd = valores[0]
            if len(valores) >= 2 and valores[1] is not None:
                saldo_ant_pyg = valores[1]
            # Esta fila no es detalle de movimiento
            continue

        # Detectar si la fila es "motivo" o "detalle"
        date_idx = next((i for i, c in enumerate(strip_cells) if rx_fecha_cell.match(c)), None)

        if ing_egr and date_idx is None:
            # Fila de MOTIVO (texto)
            motivo_actual = line_join.strip()
            continue

        # Fila de DETALLE (tiene una celda fecha)
        if ing_egr and motivo_actual and date_idx is not None:
            fecha_oper = strip_cells[date_idx]

            # SUCURSAL: primera celda no vac√≠a despu√©s de la fecha
            suc_idx = _first_non_empty_after(strip_cells, date_idx)
            sucursal = _get_cell(strip_cells, suc_idx, default='')

            # RECIBO: primera no vac√≠a despu√©s de SUCURSAL (no parseamos n√∫mero del texto de sucursal)
            rec_idx = _first_non_empty_after(strip_cells, suc_idx) if suc_idx is not None else None
            recibo_raw = _get_cell(strip_cells, rec_idx, default='')
            recibo_digits = _only_digits(recibo_raw)
            recibo = recibo_digits if recibo_digits != '' else recibo_raw

            # BULTOS
            bul_idx = _first_non_empty_after(strip_cells, rec_idx) if rec_idx is not None else None
            bultos = _get_cell(strip_cells, bul_idx, default='')

            # GUARANIES
            gua_idx = _first_non_empty_after(strip_cells, bul_idx) if bul_idx is not None else None
            guaranies = _get_cell(strip_cells, gua_idx, default='0') or '0'

            # DOLARES
            usd_idx = _first_non_empty_after(strip_cells, gua_idx) if gua_idx is not None else None
            dolares = _get_cell(strip_cells, usd_idx, default='0') or '0'

            registros.append({
                'FECHA_OPER': fecha_oper,
                'SUCURSAL': sucursal,
                'RECIBO': recibo,
                'BULTOS': bultos,
                'GUARANIES': guaranies,
                'DOLARES': dolares,
                'ING_EGR': ing_egr,
                'CLASIFICACION': clasificacion,
                'FECHA_ARCHIVO': fecha_archivo,
                'MOTIVO_MOVIMIENTO': motivo_actual,
                'AGENCIA': agencia,
                'SALDO_ANTERIOR_PYG': saldo_ant_pyg,
                'SALDO_ANTERIOR_USD': saldo_ant_usd,
            })

    # DataFrame final ordenado
    df_out = pd.DataFrame(registros)
    if df_out.empty:
        # Creamos estructura vac√≠a para no romper el flujo, pero avisamos
        df_out = pd.DataFrame(columns=[
            'FECHA_OPER', 'SUCURSAL', 'RECIBO', 'BULTOS', 'GUARANIES', 'DOLARES',
            'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO', 'AGENCIA', 'SALDO_ANTERIOR_PYG', 'SALDO_ANTERIOR_USD'
        ])
        logger.error(f'[EC_ATM] {filename}: No se detectaron registros v√°lidos.')

    df_out = _ordenar_y_renombrar_columnas_ec(df_out)
    df_out.to_excel(path_salida, index=False)
    logger.info(f'[EC_ATM] Guardado: {path_salida}')
    return path_salida

def get_ec_banco(fecha_ejecucion: datetime,
                 filename: str,
                 dir_entrada: str,
                 dir_consolidado: str,
                 sheet_name=None) -> Optional[str]:
    """
    Procesa un archivo EC_BANCO*.xlsx desde dir_entrada y genera un Excel procesado en dir_consolidado.
    Usa IMPORTE + MONEDA (una sola columna de monto con su moneda).
    Devuelve la ruta de salida o None si no se obtuvieron registros.
    """
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    hojas = _leer_hojas_excel(path_entrada, sheet_name=sheet_name)

    # Regex √∫tiles
    rx_fecha_linea = re.compile(r'^\s*(\d{1,2}/\d{1,2}/\d{4})\b')
    rx_totales = re.compile(r'\b(TOTAL|SUBTOTAL)\b', re.IGNORECASE)
    rx_moneda = re.compile(r'\b(GUARAN[I√ç]ES|D[√ìO]LARES|EUROS?|REALES?|PESOS?)\b', re.IGNORECASE)

    mapa_clasif = {
        'BANCO': 'BCO',
        'ATM': 'ATM',
        'BULTOS DE BANCO': 'BULTO BCO',
        'BULTOS DE ATM': 'BULTO ATM',
    }

    registros = []

    for nombre_hoja, df in hojas.items():
        df = df.fillna('')

        agencia = ''
        fecha_archivo = ''
        clasificacion = ''
        ing_egr = ''           # IN / OUT
        motivo_actual = ''

        # saldo anterior por HOJA (moneda)
        saldo_anterior_hoja = 0

        # Intentar leer SALDO ANTERIOR a nivel de hoja (soporta celdas combinadas)
        try:
            _saldos_hoja = _extraer_saldos_en_df(df, max_take=2)
            if _saldos_hoja:
                # Para EC_BANCO nos basta un valor: tomamos el primero
                saldo_anterior_hoja = _saldos_hoja[0] or 0
        except Exception as e:
            logger.info(f"[EC_BANCO] {filename} / hoja {nombre_hoja}: no se pudo determinar SALDO ANTERIOR global ({e}).")

        # Moneda por defecto: intento por nombre de hoja; si no, GUARANIES
        moneda_actual = _guess_currency_from_sheet_name(nombre_hoja) or 'GUARANIES'

        for _, row in df.iterrows():
            row_vals = [str(x).strip() for x in row.values]
            linea = ' '.join([v for v in row_vals if v])
            if not linea:
                continue

            linea_up = _strip_accents(linea).upper()

            # --- SALDO ANTERIOR por hoja ---
            if 'SALDO ANTERIOR' in linea_up and not saldo_anterior_hoja:
                vals = _extraer_saldos_desde_fila(row_vals)
                if vals:
                    # En EC_BANCO: tomamos el primer valor no vac√≠o a la derecha
                    saldo_anterior_hoja = vals[0] or 0
                continue

            # Agencia
            if 'PROSEGUR PARAGUAY S.A.' in linea_up:
                m = re.search(r'SUCURSAL:\s*([^)]+)\)', linea, flags=re.IGNORECASE)
                if m:
                    agencia = m.group(1).strip()
                continue

            # Clasificaci√≥n y fecha de archivo
            if 'ESTADO DE CUENTA DE' in linea_up:
                m_tipo = re.search(r'ESTADO DE CUENTA DE\s+(.*?)\s+AL:', linea, flags=re.IGNORECASE)
                if m_tipo:
                    texto = m_tipo.group(1).strip()
                    texto_norm = _strip_accents(texto).upper()
                    clasificacion = mapa_clasif.get(texto_norm, texto.strip())
                m_f = re.search(r'AL:\s*(\d{1,2}/\d{1,2}/\d{4})', linea, flags=re.IGNORECASE)
                if m_f:
                    fecha_archivo = m_f.group(1)
                continue

            # Secciones IN/OUT
            if linea_up == 'INGRESOS':
                ing_egr = 'IN'
                motivo_actual = ''
                continue
            if linea_up == 'EGRESOS':
                ing_egr = 'OUT'
                motivo_actual = ''
                continue

            # Fin del bloque √∫til
            if 'INFORME DE PROCESOS' in linea_up:
                break

            # Saltar totales/subtotales
            if rx_totales.search(linea):
                continue

            # Detectar/actualizar moneda en encabezados
            m_moneda = rx_moneda.search(linea)
            if m_moneda:
                moneda_actual = _normaliza_moneda_iso(m_moneda.group(1))
                continue

            # Encabezado de motivo (l√≠nea no-fecha dentro de IN/OUT)
            if ing_egr and not rx_fecha_linea.match(linea):
                motivo_actual = linea.strip()
                continue

            # Fila de detalle (comienza con fecha)
            m_date = rx_fecha_linea.match(linea)
            if ing_egr and motivo_actual and m_date:
                parts = linea.split()
                if not parts:
                    continue

                fecha_oper = parts[0]

                # √çndice del recibo (primer n√∫mero con al menos 6 d√≠gitos)
                idx_rec = next(
                    (i for i, p in enumerate(parts[1:], 1) if re.fullmatch(r'\d{6,}', p)),
                    None
                )
                if idx_rec is None:
                    # si no hay recibo claro, omitimos para evitar falsos positivos
                    continue

                sucursal = ' '.join(parts[1:idx_rec]).strip()
                recibo = parts[idx_rec]
                bultos = parts[idx_rec + 1] if idx_rec + 1 < len(parts) else ''
                importe = parts[idx_rec + 2] if idx_rec + 2 < len(parts) else ''

                registros.append({
                    'HOJA_ORIGEN': nombre_hoja,
                    'AGENCIA': agencia,
                    'FECHA_ARCHIVO': fecha_archivo,
                    'ING_EGR': ing_egr,
                    'CLASIFICACION': clasificacion,
                    'MOTIVO MOVIMIENTO': motivo_actual,  # se normaliza luego
                    'FECHA_OPER': fecha_oper,
                    'SUCURSAL': sucursal,
                    'RECIBO': recibo,
                    'BULTOS': bultos,
                    "MONEDA": _normaliza_moneda_iso(moneda_actual),
                    'MONTO': importe,
                    'SALDO_ANTERIOR': saldo_anterior_hoja,
                })

    # DataFrame base
    df_out = pd.DataFrame(registros, columns=[
        'HOJA_ORIGEN', 'AGENCIA', 'FECHA_ARCHIVO', 'ING_EGR', 'CLASIFICACION',
        'MOTIVO MOVIMIENTO', 'FECHA_OPER', 'SUCURSAL',
        'RECIBO', 'BULTOS', 'MONEDA', 'MONTO', 'SALDO_ANTERIOR'
    ])

    if df_out.empty:
        # Creamos estructura vac√≠a para no romper el flujo
        df_out = pd.DataFrame(columns=[
            'HOJA_ORIGEN', 'AGENCIA', 'FECHA_ARCHIVO', 'ING_EGR', 'CLASIFICACION',
            'MOTIVO MOVIMIENTO', 'FECHA_OPER', 'SUCURSAL',
            'RECIBO', 'BULTOS', 'MONEDA', 'MONTO', 'SALDO_ANTERIOR'
        ])
        logger.error(f'[EC_BANCO] {filename}: No se detectaron registros v√°lidos.')

    # Normalizar encabezados y ordenar
    df_out = df_out.rename(columns={'MOTIVO MOVIMIENTO': 'MOTIVO_MOVIMIENTO'})
    df_out = _ordenar_y_renombrar_columnas_ec_banco(df_out)

    # Guardar
    df_out.to_excel(path_salida, index=False)
    logger.info(f'[EC_BANCO] Guardado: {path_salida}')
    return path_salida

def get_ec_bultos_atm(fecha_ejecucion: datetime,
                      filename: str,
                      dir_entrada: str,
                      dir_consolidado: str,
                      sheet_name: Union[int, str] = 0,
                      descartar_usd_cero: bool = True) -> Optional[str]:
    """
    Procesa 'EC_BULTOS_ATM*.xlsx' en formato LONG (una fila por moneda: PYG, USD).
    - Genera salida en dir_consolidado con sufijo '_PROCESADO.xlsx'
    - Si descartar_usd_cero=True, no genera fila USD cuando IMPORTE USD==0
    Devuelve la ruta de salida o None si no hubo registros.
    """
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    df_x = pd.read_excel(path_entrada, sheet_name=sheet_name, header=None, dtype=str).fillna('')

    rx_fecha_cell = re.compile(r'^\s*\d{1,2}/\d{1,2}/\d{4}\s*$')
    rx_totales = re.compile(r'\b(TOTAL|SUBTOTAL)\b', re.IGNORECASE)

    agencia = ''
    fecha_archivo = ''
    clasificacion = 'ATM'
    ing_egr = ''
    motivo_actual = ''

    registros: List[Dict[str, str]] = []

    # Ahora empezamos sin saldo, los llenamos cuando veamos la fila de SALDO ANTERIOR
    saldo_ant_pyg: Optional[int] = None
    saldo_ant_usd: Optional[int] = None

    for _, row in df_x.iterrows():
        cells = [str(x) if x is not None else '' for x in row.values]
        strip_cells = [c.strip() for c in cells]
        line_join = ' '.join([c for c in strip_cells if c])
        if not line_join:
            continue

        upper_join = _strip_accents(line_join).upper()

        # Encabezados
        if 'PROSEGUR PARAGUAY S.A.' in upper_join:
            m = re.search(r'SUCURSAL:\s*([^)]+)\)', line_join, flags=re.IGNORECASE)
            if m:
                agencia = m.group(1).strip()
            continue

        if 'ESTADO DE CUENTA DE BULTOS DE ATM' in upper_join:
            m_f = re.search(r'AL:\s*(\d{1,2}/\d{1,2}/\d{4})', line_join, flags=re.IGNORECASE)
            if m_f:
                fecha_archivo = m_f.group(1)
            continue

        if upper_join == 'INGRESOS':
            ing_egr = 'IN'
            motivo_actual = ''
            continue

        if upper_join == 'EGRESOS':
            ing_egr = 'OUT'
            motivo_actual = ''
            continue

        if 'INFORME DE PROCESOS' in upper_join:
            # fin del bloque √∫til
            break

        if rx_totales.search(line_join):
            # ignorar l√≠neas de totales/subtotales
            continue

        # SALDO ANTERIOR:
        if 'SALDO ANTERIOR' in upper_join and not (saldo_ant_pyg or saldo_ant_usd):
            # Usamos toda la fila, tal como viene del Excel
            vals = _extraer_saldos_desde_fila(cells)

            # Queremos ignorar las "cantidades de bultos" y quedarnos con los saldos.
            # Suponemos que los saldos son valores "grandes" (>= 1000) y las cantidades son peque&ntilde;as.
            grandes_idx = [i for i, v in enumerate(vals) if v >= 1000]

            if grandes_idx:
                # Primer saldo grande = PYG
                saldo_ant_pyg = vals[grandes_idx[0]]
                # Segundo saldo grande (si existe) = USD
                if len(grandes_idx) > 1:
                    saldo_ant_usd = vals[grandes_idx[1]]
                else:
                    # Si s&oacute;lo hay un saldo grande, el USD normalmente es 0
                    saldo_ant_usd = 0
            else:
                # Caso extremo: todo son 0,00 (saldo realmente cero),
                # hacemos fallback a la posici&oacute;n original por si acaso
                if len(vals) >= 2:
                    saldo_ant_pyg = vals[1] or 0
                if len(vals) >= 4:
                    saldo_ant_usd = vals[3] or 0

            # Esta fila no es detalle de movimiento
            continue

        # Buscar fecha en la fila
        date_idx = next((i for i, c in enumerate(strip_cells) if rx_fecha_cell.match(c)), None)

        # Si no hay fecha, puede ser MOTIVO
        if ing_egr and date_idx is None:
            motivo_actual = line_join.strip()
            continue

        # Fila de detalle (tiene fecha + hay ING/EG y motivo)
        if ing_egr and motivo_actual and date_idx is not None:
            fecha_oper = strip_cells[date_idx]

            # Sucursal
            suc_idx = _first_non_empty_after(strip_cells, date_idx)
            sucursal = _get_cell(strip_cells, suc_idx, default='')

            # Recibo
            rec_idx = _first_non_empty_after(strip_cells, suc_idx) if suc_idx is not None else None
            recibo_raw = _get_cell(strip_cells, rec_idx, default='')
            recibo_digits = _only_digits(recibo_raw)
            recibo = recibo_digits if recibo_digits != '' else recibo_raw

            # Bultos y montos por moneda: PYG primero, luego USD
            b_pyg_idx = _first_non_empty_after(strip_cells, rec_idx)
            bultos_pyg = _get_cell(strip_cells, b_pyg_idx, default='0') or '0'

            gua_idx = _first_non_empty_after(strip_cells, b_pyg_idx)
            guaranies = _get_cell(strip_cells, gua_idx, default='0') or '0'

            b_usd_idx = _first_non_empty_after(strip_cells, gua_idx)
            bultos_usd = _get_cell(strip_cells, b_usd_idx, default='0') or '0'

            usd_idx = _first_non_empty_after(strip_cells, b_usd_idx)
            dolares = _get_cell(strip_cells, usd_idx, default='0') or '0'

            # Fila PYG (se rellenan ambos saldos anteriores)
            registros.append({
                'FECHA_OPER': fecha_oper,
                'SUCURSAL': sucursal,
                'RECIBO': recibo,
                'BULTOS': bultos_pyg,
                'MONEDA': 'PYG',
                'IMPORTE': guaranies,
                'ING_EGR': ing_egr,
                'CLASIFICACION': clasificacion,
                'FECHA_ARCHIVO': fecha_archivo,
                'MOTIVO_MOVIMIENTO': motivo_actual,
                'AGENCIA': agencia,
                'SALDO_ANTERIOR_PYG': saldo_ant_pyg or 0,
                'SALDO_ANTERIOR_USD': saldo_ant_usd or 0,
            })

            # Fila USD (opcional si importe != 0)
            if not (descartar_usd_cero and _is_zero_like(dolares)):
                registros.append({
                    'FECHA_OPER': fecha_oper,
                    'SUCURSAL': sucursal,
                    'RECIBO': recibo,
                    'BULTOS': bultos_usd,
                    'MONEDA': 'USD',
                    'IMPORTE': dolares,
                    'ING_EGR': ing_egr,
                    'CLASIFICACION': clasificacion,
                    'FECHA_ARCHIVO': fecha_archivo,
                    'MOTIVO_MOVIMIENTO': motivo_actual,
                    'AGENCIA': agencia,
                    'SALDO_ANTERIOR_PYG': saldo_ant_pyg or 0,
                    'SALDO_ANTERIOR_USD': saldo_ant_usd or 0,
                })

    # DataFrame de salida
    df_out = pd.DataFrame(registros)
    if df_out.empty:
        df_out = pd.DataFrame(columns=[
            'FECHA_OPER', 'SUCURSAL', 'RECIBO', 'BULTOS', 'MONEDA', 'IMPORTE',
            'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
            'AGENCIA', 'SALDO_ANTERIOR_PYG', 'SALDO_ANTERIOR_USD'
        ])
        logger.error(f'[EC_BULTOS_ATM] {filename}: No se detectaron registros v√°lidos.')

    # Ordenar/renombrar columnas seg√∫n helper
    df_out = _ordenar_y_renombrar_columnas_bultos(df_out)

    # Normalizar c√≥digo de moneda (por si en alg√∫n caso no vienen exactos)
    if 'MONEDA' in df_out.columns:
        df_out['MONEDA'] = df_out['MONEDA'].apply(_normaliza_moneda_iso)

    # Guardar
    df_out.to_excel(path_salida, index=False)
    logger.info(f'[EC_BULTOS_ATM] Guardado: {path_salida}')
    return path_salida


def get_ec_bultos_bco(fecha_ejecucion: datetime,
                       filename: str,
                       dir_entrada: str,
                       dir_consolidado: str,
                       sheet_name=None) -> Optional[str]:
    """
    Procesa archivos 'EC_BULTOS_BCO*.xlsx' / 'EC_BULTOS_BANCO*.xlsx' en formato LONG:
      FECHA, SUCURSAL, RECIBO, BULTOS, MONEDA(ISO), IMPORTE, ING_EGR, CLASIFICACION, FECHA_ARCHIVO,
      MOTIVO_MOVIMIENTO, AGENCIA, SALDO_ANTERIOR, HOJA_ORIGEN.
    - Detecta moneda por nombre de hoja, encabezados o en l√≠nea (prioridad en ese orden).
    - Clasificaci√≥n por encabezado ('ESTADO DE CUENTA DE ...'), default 'BULTO BCO'.
    Devuelve ruta de salida o None si no hubo registros.
    """
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    # Cargar hojas (si sheet_name=None -> todas)
    if sheet_name is None:
        hojas = pd.read_excel(path_entrada, sheet_name=None, header=None, dtype=str)
    elif isinstance(sheet_name, (list, tuple)):
        hojas = pd.read_excel(path_entrada, sheet_name=list(sheet_name), header=None, dtype=str)
    else:
        df_one = pd.read_excel(path_entrada, sheet_name=sheet_name, header=None, dtype=str)
        hojas = {sheet_name: df_one}

    rx_fecha_linea = re.compile(r'^\s*(\d{1,2}/\d{1,2}/\d{4})\b')
    rx_totales = re.compile(r'\b(TOTAL|SUBTOTAL)\b', re.IGNORECASE)
    # Incluye s√≠mbolos: ‚Ç≤, G$, US$, U$S, R$, ‚Ç¨, $
    rx_moneda = re.compile(
        r'(GUARAN[I√ç]ES|D[√ìO]LARES|EUROS?|REALES?|PESOS?|PYG|GS|G\$|‚Ç≤|USD|US\$|U\$S|R\$|BRL|EUR|ARS|‚Ç¨|\$)',
        re.IGNORECASE
    )

    mapa_clasif = {
        'BANCO': 'BCO',
        'ATM': 'ATM',
        'BULTOS DE BANCO': 'BULTO BCO',
        'BULTOS DE ATM': 'BULTO ATM',
    }

    registros: List[Dict[str, Any]] = []

    for nombre_hoja, df in hojas.items():
        df = df.fillna('')

        agencia = ''
        fecha_archivo = ''
        clasificacion = 'BULTO BCO'  # por defecto
        ing_egr = ''                 # IN/OUT
        motivo_actual = ''
        saldo_anterior_hoja = None   # üëâ importante: None para saber si ya lo le√≠mos

        # Moneda por defecto: por nombre de hoja; si no, asumimos PYG
        moneda_actual = _normaliza_moneda_iso(nombre_hoja)

        for _, row in df.iterrows():
            # Valores crudos de la fila
            row_vals = [str(x) if x is not None else '' for x in row.values]
            parts_all = [v.strip() for v in row_vals if v.strip()]
            linea = ' '.join(parts_all)
            if not linea:
                continue

            linea_up = _strip_accents(linea).upper()

            # --- SALDO ANTERIOR por hoja ---
            if 'SALDO ANTERIOR' in linea_up and not saldo_anterior_hoja:
                # Tomamos la fila completa y buscamos los n√∫meros a la derecha
                valores = _extraer_saldos_desde_fila(row_vals)

                # Patr√≥n t√≠pico en BULTOS_BCO: [cant_bultos, saldo]
                # Queremos ignorar la cantidad de bultos y quedarnos con el saldo.
                # De nuevo, consideramos "saldo" como un valor grande (>= 1000).
                grandes = [v for v in valores if v >= 1000]

                if grandes:
                    # Primer valor grande ‚Üí SALDO_ANTERIOR
                    saldo_anterior_hoja = grandes[0]
                elif valores:
                    # Si no hay valores grandes pero hay algo (ej. todo 0),
                    # nos quedamos con el √∫ltimo valor.
                    saldo_anterior_hoja = valores[-1] or 0
                else:
                    saldo_anterior_hoja = 0

                continue

            # Agencia
            if 'PROSEGUR PARAGUAY S.A.' in linea_up:
                m = re.search(r'SUCURSAL:\s*([^)]+)\)', linea, flags=re.IGNORECASE)
                if m:
                    agencia = m.group(1).strip()
                continue

            # Clasificaci√≥n + fecha de archivo
            if 'ESTADO DE CUENTA DE' in linea_up:
                m_tipo = re.search(r'ESTADO DE CUENTA DE\s+(.*?)\s+AL[:\s]', linea, flags=re.IGNORECASE)
                if m_tipo:
                    texto = m_tipo.group(1).strip()
                    texto_norm = _strip_accents(texto).upper()
                    clasificacion = mapa_clasif.get(texto_norm, texto.strip()) or clasificacion
                m_f = re.search(r'AL[:\s]+(\d{1,2}/\d{1,2}/\d{4})', linea, flags=re.IGNORECASE)
                if m_f:
                    fecha_archivo = m_f.group(1)
                # si aparece moneda en el encabezado, usarla
                m_mon_enc = rx_moneda.search(linea)
                if m_mon_enc:
                    moneda_actual = _normaliza_moneda_iso(m_mon_enc.group(1))
                continue

            # Secciones IN/OUT
            if linea_up == 'INGRESOS':
                ing_egr = 'IN'
                motivo_actual = ''
                continue
            if linea_up == 'EGRESOS':
                ing_egr = 'OUT'
                motivo_actual = ''
                continue

            # Fin del bloque √∫til
            if 'INFORME DE PROCESOS' in linea_up:
                break

            # Saltar totales/subtotales
            if rx_totales.search(linea):
                continue

            # Si vemos token de MONEDA fuera de detalle (sin fecha al inicio), actualizamos contexto
            if rx_moneda.search(linea) and not rx_fecha_linea.match(linea):
                moneda_actual = _normaliza_moneda_iso(rx_moneda.search(linea).group(1))
                continue

            # Encabezado de MOTIVO (l√≠nea no-fecha dentro de IN/OUT)
            if ing_egr and not rx_fecha_linea.match(linea):
                motivo_actual = linea.strip()
                continue

            # Detalle (empieza con fecha)
            m_date = rx_fecha_linea.match(linea)
            if ing_egr and motivo_actual and m_date:
                parts = parts_all
                if not parts:
                    continue

                fecha_oper = parts[0]

                # √çndice del recibo: primer n√∫mero con >=6 d√≠gitos
                idx_rec = next(
                    (i for i, p in enumerate(parts[1:], 1) if re.fullmatch(r'\d{6,}', _strip_accents(p))),
                    None
                )
                if idx_rec is None:
                    # muy conservador: si no hay recibo claro, no registramos
                    continue

                sucursal = ' '.join(parts[1:idx_rec]).strip()
                recibo = parts[idx_rec]
                bultos = parts[idx_rec + 1] if idx_rec + 1 < len(parts) else ''
                importe = parts[idx_rec + 2] if idx_rec + 2 < len(parts) else ''

                # √öltima chance: si en la misma l√≠nea aparece un token de moneda, usarlo
                m_mon_inline = rx_moneda.search(linea)
                if m_mon_inline:
                    moneda_actual = _normaliza_moneda_iso(m_mon_inline.group(1))

                registros.append({
                    'FECHA': fecha_oper,           # ya con nombre final
                    'SUCURSAL': sucursal,
                    'RECIBO': recibo,
                    'BULTOS': bultos,
                    'MONEDA': moneda_actual or 'PYG',
                    'IMPORTE': importe,
                    'ING_EGR': ing_egr,
                    'CLASIFICACION': clasificacion,
                    'FECHA_ARCHIVO': fecha_archivo,
                    'MOTIVO_MOVIMIENTO': motivo_actual,
                    'AGENCIA': agencia,
                    'SALDO_ANTERIOR': saldo_anterior_hoja or 0,
                    'HOJA_ORIGEN': nombre_hoja,
                })

    # DataFrame base
    df_out = pd.DataFrame(registros, columns=[
        'FECHA', 'SUCURSAL', 'RECIBO', 'BULTOS', 'MONEDA', 'IMPORTE',
        'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
        'AGENCIA', 'SALDO_ANTERIOR', 'HOJA_ORIGEN'
    ])

    if df_out.empty:
        df_out = pd.DataFrame(columns=[
            'FECHA', 'SUCURSAL', 'RECIBO', 'BULTOS', 'MONEDA', 'IMPORTE',
            'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
            'AGENCIA', 'SALDO_ANTERIOR', 'HOJA_ORIGEN'
        ])
        logger.error(f'[EC_BULTOS_BCO] {filename}: No se detectaron registros v√°lidos.')

    # Orden final espec√≠fico de BULTOS BANCO (una sola columna SALDO_ANTERIOR)
    df_out = _ordenar_y_renombrar_columnas_bultos_bco(df_out)

    # Normalizar c√≥digo de moneda por si acaso
    if 'MONEDA' in df_out.columns:
        df_out['MONEDA'] = df_out['MONEDA'].apply(_normaliza_moneda_iso)

    # Guardar salida
    df_out.to_excel(path_salida, index=False)
    logger.info(f'[EC_BULTOS_BCO] Guardado: {path_salida}')
    return path_salida


def get_inv_atm(fecha_ejecucion: datetime,
                filename: str,
                dir_entrada: str,
                dir_consolidado: str,
                include_zeros: bool = True) -> Optional[str]:
    """
    Procesa un archivo 'INV_BILLETES_ATM*.xls[x]' y genera un Excel procesado en dir_consolidado.
    Columnas de salida:
      FECHA_INVENTARIO, DIVISA, AGENCIA, AGRUPACION_EFECTIVO, TIPO_VALOR,
      DENOMINACION, DEPOSITO, CJE_DEP, CANJE, MONEDA, IMPORTE_TOTAL
    """
    # ---- Config/tokens espec√≠ficos de INV ATM ----
    AGRUP_TOKENS = ["TESORO ATM", "FAJOS ATM", "PICOS ATM"]
    TIPO_TOKENS  = ["BILLETES (LADRILLOS)", "BILLETES"]  # orden importa
    FIN_MONEDA_UP = "TOTAL DE LA MONEDA"
    STOP_ROW_TOKENS = {
        "SUB TOTAL", "SUBTOTAL", "TOTAL DEL DEP√ìSITO", "TOTAL DEL DEPOSITO",
        "TOTAL DEP√ìSITO", "TOTAL DEPOSITO"
    }
    DATE_RE    = re.compile(r"(\d{2}/\d{2}/\d{4})")
    AGENCIA_RE = re.compile(r"SUCURSAL:\s*([^)]+)\)", re.IGNORECASE)
    TITULO_RE  = re.compile(r"SALDO DE INVENTARIO DE BILLETES ATM AL", re.IGNORECASE)

    def normaliza_divisa_code(code_upper: str) -> str:
        return _normaliza_moneda_iso(code_upper)

    # ---- Paths ----
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    # ---- Helpers internos de INV ----
    def extrae_agencia_y_fecha(df: pd.DataFrame) -> Dict[str, str]:
        agencia, fecha = "", ""
        for _, row in df.iterrows():
            for cell in row:
                t = _txt(cell)
                if not agencia:
                    m = AGENCIA_RE.search(t)
                    if m:
                        agencia = m.group(1).strip()
                if not fecha and (TITULO_RE.search(t) or "SALDO DE INVENTARIO" in t.upper()):
                    m = DATE_RE.search(t)
                    if m:
                        fecha = m.group(1)
            if agencia and fecha:
                break
        if not fecha:
            for _, row in df.iterrows():
                for cell in row:
                    m = DATE_RE.search(_txt(cell))
                    if m:
                        fecha = m.group(1)
                        break
                if fecha:
                    break
        return {"AGENCIA": agencia, "FECHA_INVENTARIO": fecha}

    def capturar_codigo_total(row_text_upper: str) -> Optional[str]:
        m = re.search(r"TOTAL\s+DE\s+LA\s+MONEDA\s+([A-Z]{3})", row_text_upper, flags=re.IGNORECASE)
        return m.group(1).upper() if m else None

    def buscar_fin_y_codigo(df: pd.DataFrame) -> Tuple[int, Optional[str]]:
        row_end, code = len(df), None
        for i, row in df.iterrows():
            row_up = " | ".join(_upper(c) for c in row.tolist())
            if FIN_MONEDA_UP in row_up:
                row_end = i
                code = capturar_codigo_total(row_up)
                break
        return row_end, code

    def buscar_inicio_por_divisa(df: pd.DataFrame, row_end: int) -> Optional[int]:
        for i, row in df.iterrows():
            if i >= row_end:
                break
            ups = [_upper(c) for c in row.tolist() if _txt(c)]
            if "USD" in ups or "PYG" in ups:
                return i
        return None

    def buscar_inicio_fallback(df: pd.DataFrame, row_end: int) -> Optional[int]:
        for i, row in df.iterrows():
            if i >= row_end:
                break
            nums = [j for j, c in enumerate(row.tolist()) if _to_int(c) is not None]
            if not nums:
                continue
            denom_col = nums[0]
            left_up = " ".join(_upper(row.iloc[j]) for j in range(0, denom_col) if _txt(row.iloc[j]))
            if any(tok in left_up for tok in AGRUP_TOKENS):
                return i
        return None

    def localiza_bloque(df: pd.DataFrame) -> Dict[str, Any]:
        row_end, code_total = buscar_fin_y_codigo(df)
        row_start = buscar_inicio_por_divisa(df, row_end)
        if row_start is None:
            row_start = buscar_inicio_fallback(df, row_end)
        if row_start is None:
            raise ValueError("No se pudo determinar el inicio del bloque (no se encontr√≥ USD/PYG ni agrupaci√≥n con denominaci√≥n).")
        return {"row_start": row_start, "row_end": row_end, "moneda_codigo": code_total}

    def fila_es_total_o_subtotal(row) -> bool:
        up = " ".join(_upper(c) for c in row.tolist())
        return any(tok in up for tok in STOP_ROW_TOKENS) or FIN_MONEDA_UP in up

    def lista_numeros_con_indices(row) -> List[Tuple[int, int]]:
        out = []
        for j, c in enumerate(row.tolist()):
            v = _to_int(c)
            if v is not None:
                out.append((j, v))
        return out

    def siguiente_numero_a_la_derecha(row, desde_col: int) -> Tuple[int, int]:
        ncols = len(row)
        for j in range(desde_col + 1, ncols):
            v = _to_int(row.iloc[j])
            if v is not None:
                return j, v
        return ncols, 0

    def detectar_agrup_y_tipo(left_cells: List[str]) -> Tuple[Optional[str], Optional[str]]:
        left_up = " ".join(_upper(c) for c in left_cells if _txt(c))
        tipo = None
        for t in TIPO_TOKENS:
            if t in left_up:
                tipo = t
                break
        agrup = None
        for a in AGRUP_TOKENS:
            if a in left_up:
                agrup = a
                break
        return agrup, tipo

    def parsea_cuerpo(df: pd.DataFrame, row_start: int, row_end: int, default_code: Optional[str],
                      agencia: str, fecha: str) -> List[Dict[str, Any]]:
        registros: List[Dict[str, Any]] = []
        cur_divisa = normaliza_divisa_code(default_code or "")
        cur_agrup, cur_tipo = "", ""

        for i in range(row_start, row_end):
            row = df.iloc[i]
            if fila_es_total_o_subtotal(row):
                continue

            ups = [_upper(c) for c in row.tolist() if _txt(c)]
            if "USD" in ups:
                cur_divisa = "USD"
            elif "PYG" in ups:
                cur_divisa = "PYG"

            nums = lista_numeros_con_indices(row)
            if not nums:
                continue
            denom_col, denom_val = nums[0]

            left_cells = [row.iloc[j] for j in range(0, denom_col)]
            agrup, tipo = detectar_agrup_y_tipo(left_cells)
            if agrup:
                cur_agrup = agrup
            if tipo:
                cur_tipo = tipo

            # Tomar los 5 n√∫meros siguientes (DEPOSITO,CJE_DEP,CANJE,MONEDA,IMPORTE_TOTAL)
            idx = denom_col
            vals = []
            for _ in range(5):
                idx, v = siguiente_numero_a_la_derecha(row, idx)
                vals.append(v)
            while len(vals) < 5:
                vals.append(0)

            reg = {
                "FECHA_INVENTARIO": fecha,
                "DIVISA": cur_divisa or "PYG",
                "AGENCIA": agencia,
                "AGRUPACION_EFECTIVO": cur_agrup,
                "TIPO_VALOR": cur_tipo,
                "DENOMINACION": denom_val,
                "DEPOSITO": vals[0] or 0,
                "CJE_DEP": vals[1] or 0,
                "CANJE": vals[2] or 0,
                "MONEDA": vals[3] or 0,
                "IMPORTE_TOTAL": vals[4] or 0,
            }
            if include_zeros or any([reg["DEPOSITO"], reg["CJE_DEP"], reg["CANJE"], reg["MONEDA"], reg["IMPORTE_TOTAL"]]):
                registros.append(reg)

        return registros

    # ---- Procesar el archivo (todas las hojas) ----
    try:
        xls = pd.ExcelFile(path_entrada, engine="openpyxl")
    except Exception as e:
        logger.error(f"[INV_ATM] {filename}: No se pudo abrir el archivo ({e}).")
        return None

    registros: List[Dict[str, Any]] = []
    for sheet in xls.sheet_names:
        try:
            df = pd.read_excel(path_entrada, sheet_name=sheet, header=None, dtype=object, engine="openpyxl").fillna("")
            meta = extrae_agencia_y_fecha(df)
            lim = localiza_bloque(df)
            registros.extend(
                parsea_cuerpo(df, lim["row_start"], lim["row_end"], lim.get("moneda_codigo"),
                              meta.get("AGENCIA", ""), meta.get("FECHA_INVENTARIO", ""))
            )
        except Exception as e:
            # si una hoja falla, continuamos con las dem√°s
            logger.info(f"[INV_ATM] Hoja '{sheet}' omitida: {e}")
            continue

    if not registros:
        logger.error(f"[INV_ATM] {filename}: No se extrajeron filas.")
        # guardo estructura vac√≠a para mantener el flujo
        cols = ["FECHA_INVENTARIO","DIVISA","AGENCIA","AGRUPACION_EFECTIVO","TIPO_VALOR",
                "DENOMINACION","DEPOSITO","CJE_DEP","CANJE","MONEDA","IMPORTE_TOTAL"]
        pd.DataFrame(columns=cols).to_excel(path_salida, index=False)
        logger.info(f'[INV_ATM] Guardado vac√≠o: {path_salida}')
        return path_salida

    df_out = pd.DataFrame(registros)[[
    "FECHA_INVENTARIO","DIVISA","AGENCIA",
    "AGRUPACION_EFECTIVO","TIPO_VALOR",
    "DENOMINACION","DEPOSITO","CJE_DEP","CANJE","MONEDA","IMPORTE_TOTAL"
    ]]

    # Re-normalizar por si se col√≥ alg√∫n "GUARANIES", "DOLARES", etc.
    df_out["DIVISA"] = df_out["DIVISA"].apply(_normaliza_moneda_iso)

    df_out.sort_values(by=[
        "FECHA_INVENTARIO","AGENCIA","DIVISA",
        "AGRUPACION_EFECTIVO","TIPO_VALOR","DENOMINACION"
    ], inplace=True)

    # ---- Guardar ----
    df_out.to_excel(path_salida, index=False)
    logger.info(f"[INV_ATM] {filename}: {len(registros)} filas extra√≠das.")
    return path_salida


def get_inv_bco(fecha_ejecucion: datetime,
                filename: str,
                dir_entrada: str,
                dir_consolidado: str,
                include_zeros: bool = True) -> Optional[str]:
    """
    Procesa un archivo 'INV_BILLETES_BANCO*.xls[x]' y genera un Excel procesado en dir_consolidado.
    Columnas de salida:
      FECHA_INVENTARIO, DIVISA, AGENCIA, AGRUPACION_EFECTIVO, TIPO_VALOR,
      DENOMINACION, DEPOSITO, CJE_DEP, CANJE, MONEDA, IMPORTE_TOTAL
    """
    # ---- Config/tokens espec√≠ficos de INV BANCO ----
    AGRUP_TOKENS = ["TESORO EFECTIVO", "FAJOS EFECTIVOS", "PICOS EFECTIVO"]
    TIPO_TOKENS  = ["BILLETES (LADRILLOS)", "MONEDAS (BOLSAS)", "MONEDAS (PAQUETES)", "BILLETES", "MONEDAS"]
    FIN_MONEDA_UP = "TOTAL DE LA MONEDA"
    STOP_ROW_TOKENS = {
        "SUB TOTAL", "SUBTOTAL", "TOTAL DEL DEP√ìSITO", "TOTAL DEL DEPOSITO",
        "TOTAL DEP√ìSITO", "TOTAL DEPOSITO"
    }
    DATE_RE    = re.compile(r"(\d{2}/\d{2}/\d{4})")
    TITULO_RE  = re.compile(r"SALDOS?\s+DE\s+INVENTARIO\s+DE\s+BILLETES\s+AL", re.IGNORECASE)
    AGENCIA_RE = re.compile(r"SUCURSAL:\s*([^)]+)\)", re.IGNORECASE)

    def normaliza_divisa_code(code_upper: str) -> str:
        return _normaliza_moneda_iso(code_upper)

    # ---- Paths ----
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    # ---- Helpers internos de INV BANCO ----
    def extrae_agencia_y_fecha(df: pd.DataFrame) -> Dict[str, str]:
        agencia, fecha = "", ""
        for _, row in df.iterrows():
            for cell in row:
                t = _txt(cell)
                if not agencia:
                    m = AGENCIA_RE.search(t)
                    if m:
                        agencia = m.group(1).strip()
                if not fecha and (TITULO_RE.search(t) or "INVENTARIO" in t.upper()):
                    m = DATE_RE.search(t)
                    if m:
                        fecha = m.group(1)
            if agencia and fecha:
                break
        if not fecha:
            for _, row in df.iterrows():
                for cell in row:
                    m = DATE_RE.search(_txt(cell))
                    if m:
                        fecha = m.group(1); break
                if fecha: break
        return {"AGENCIA": agencia, "FECHA_INVENTARIO": fecha}

    def capturar_codigo_total(row_text_upper: str) -> Optional[str]:
        m = re.search(r"TOTAL\s+DE\s+LA\s+MONEDA\s+([A-Z]{3})", row_text_upper, flags=re.IGNORECASE)
        return m.group(1).upper() if m else None

    def buscar_fin_y_codigo(df: pd.DataFrame) -> Tuple[int, Optional[str]]:
        row_end, code = len(df), None
        for i, row in df.iterrows():
            row_up = " | ".join(_upper(c) for c in row.tolist())
            if FIN_MONEDA_UP in row_up:
                row_end = i
                code = capturar_codigo_total(row_up)
                break
        return row_end, code

    def buscar_inicio_por_divisa(df: pd.DataFrame, row_end: int) -> Optional[int]:
        for i, row in df.iterrows():
            if i >= row_end: break
            ups = [_upper(c) for c in row.tolist() if _txt(c)]
            if "USD" in ups or "PYG" in ups:
                return i
        return None

    def buscar_inicio_por_cabecera(df: pd.DataFrame, row_end: int) -> Optional[int]:
        for i, row in df.iterrows():
            row_up = " | ".join(_upper(c) for c in row.tolist())
            if ("DIVISA" in row_up and "DENOM" in row_up and "CJE/DEP" in row_up and "IMPORTE" in row_up):
                return i + 1
        return None

    def buscar_inicio_fallback(df: pd.DataFrame, row_end: int) -> Optional[int]:
        for i, row in df.iterrows():
            if i >= row_end: break
            nums = [j for j, c in enumerate(row.tolist()) if _to_int(c) is not None]
            if not nums: continue
            denom_col = nums[0]
            left_up = " ".join(_upper(row.iloc[j]) for j in range(0, denom_col) if _txt(row.iloc[j]))
            if any(tok in left_up for tok in AGRUP_TOKENS):
                return i
        return None

    def localiza_bloque(df: pd.DataFrame) -> Dict[str, Any]:
        row_end, code_total = buscar_fin_y_codigo(df)
        row_start = buscar_inicio_por_cabecera(df, row_end)
        if row_start is None:
            row_start = buscar_inicio_por_divisa(df, row_end)
        if row_start is None:
            row_start = buscar_inicio_fallback(df, row_end)
        if row_start is None:
            raise ValueError("No se pudo determinar el inicio del bloque (cabecera / USD-PYG / agrupaci√≥n+denominaci√≥n).")
        return {"row_start": row_start, "row_end": row_end, "moneda_codigo": code_total}

    def fila_es_total_o_subtotal(row) -> bool:
        up = " ".join(_upper(c) for c in row.tolist())
        return any(tok in up for tok in STOP_ROW_TOKENS) or FIN_MONEDA_UP in up

    def lista_numeros_con_indices(row) -> List[Tuple[int, int]]:
        out = []
        for j, c in enumerate(row.tolist()):
            v = _to_int(c)
            if v is not None:
                out.append((j, v))
        return out

    def siguiente_numero_a_la_derecha(row, desde_col: int) -> Tuple[int, int]:
        ncols = len(row)
        for j in range(desde_col + 1, ncols):
            v = _to_int(row.iloc[j])
            if v is not None:
                return j, v
        return ncols, 0

    def detectar_agrup_y_tipo(left_cells: List[str]) -> Tuple[Optional[str], Optional[str]]:
        left_up = " ".join(_upper(c) for c in left_cells if _txt(c))
        tipo = None
        for t in TIPO_TOKENS:
            if t in left_up:
                tipo = t; break
        agrup = None
        for a in AGRUP_TOKENS:
            if a in left_up:
                agrup = a; break
        return agrup, tipo

    def parsea_cuerpo(df: pd.DataFrame, row_start: int, row_end: int, default_code: Optional[str],
                      agencia: str, fecha: str) -> List[Dict[str, Any]]:
        registros: List[Dict[str, Any]] = []
        cur_divisa = normaliza_divisa_code(default_code or "")
        cur_agrup, cur_tipo = "", ""

        for i in range(row_start, row_end):
            row = df.iloc[i]
            if fila_es_total_o_subtotal(row):
                continue

            ups = [_upper(c) for c in row.tolist() if _txt(c)]
            if "USD" in ups:
                cur_divisa = normaliza_divisa_code("USD")
            elif "PYG" in ups:
                cur_divisa = normaliza_divisa_code("PYG")

            nums = lista_numeros_con_indices(row)
            if not nums:
                continue
            denom_col, denom_val = nums[0]

            left_cells = [row.iloc[j] for j in range(0, denom_col)]
            agrup, tipo = detectar_agrup_y_tipo(left_cells)
            if agrup: cur_agrup = agrup
            if tipo:  cur_tipo = tipo

            # Despu√©s de DENOM vienen 5 n√∫meros: DEPOSITO, CJE_DEP, CANJE, MONEDA, IMPORTE_TOTAL
            idx = denom_col
            vals = []
            for _ in range(5):
                idx, v = siguiente_numero_a_la_derecha(row, idx)
                vals.append(v)
            while len(vals) < 5:
                vals.append(0)

            reg = {
                "FECHA_INVENTARIO": fecha,
                "DIVISA": cur_divisa or "PYG",
                "AGENCIA": agencia,
                "AGRUPACION_EFECTIVO": cur_agrup,
                "TIPO_VALOR": cur_tipo,
                "DENOMINACION": denom_val,
                "DEPOSITO": vals[0] or 0,
                "CJE_DEP": vals[1] or 0,
                "CANJE": vals[2] or 0,
                "MONEDA": vals[3] or 0,
                "IMPORTE_TOTAL": vals[4] or 0,
            }
            if include_zeros or any([reg["DEPOSITO"], reg["CJE_DEP"], reg["CANJE"], reg["MONEDA"], reg["IMPORTE_TOTAL"]]):
                registros.append(reg)

        return registros

    # ---- Procesar el archivo (todas las hojas) ----
    try:
        xls = pd.ExcelFile(path_entrada, engine="openpyxl")
    except Exception as e:
        logger.error(f"[INV_BCO] {filename}: No se pudo abrir el archivo ({e}).")
        return None

    registros: List[Dict[str, Any]] = []
    for sheet in xls.sheet_names:
        try:
            df = pd.read_excel(path_entrada, sheet_name=sheet, header=None, dtype=object, engine="openpyxl").fillna("")
            meta = extrae_agencia_y_fecha(df)
            lim = localiza_bloque(df)
            registros.extend(
                parsea_cuerpo(df, lim["row_start"], lim["row_end"], lim.get("moneda_codigo"),
                              meta.get("AGENCIA", ""), meta.get("FECHA_INVENTARIO", ""))
            )
        except Exception as e:
            logger.info(f"[INV_BCO] Hoja '{sheet}' omitida: {e}")
            continue

    # ---- Salida ----
    cols = ["FECHA_INVENTARIO","DIVISA","AGENCIA","AGRUPACION_EFECTIVO","TIPO_VALOR",
            "DENOMINACION","DEPOSITO","CJE_DEP","CANJE","MONEDA","IMPORTE_TOTAL"]

    if not registros:
        logger.info(f"[INV_BCO] {filename}: No se extrajeron filas.")
        pd.DataFrame(columns=cols).to_excel(path_salida, index=False)
        logger.info(f'[INV_BCO] Guardado vac√≠o: {path_salida}')
        return path_salida

    df_out = pd.DataFrame(registros)[cols]
    # Normalizar DIVISA por si qued√≥ alg√∫n texto tipo "GUARANIES", "DOLARES", etc.
    df_out["DIVISA"] = df_out["DIVISA"].apply(_normaliza_moneda_iso)

    df_out.sort_values(by=[
        "FECHA_INVENTARIO","AGENCIA","DIVISA","AGRUPACION_EFECTIVO","TIPO_VALOR","DENOMINACION"
    ], inplace=True)

    df_out.to_excel(path_salida, index=False)
    logger.info(f'[INV_BCO] Guardado: {path_salida}')
    return path_salida


# ==================== L√ìGICA DE CARPETAS / ORQUESTACI√ìN ====================

def colectar_pendientes(base_path: Path) -> List[Tuple[Path, str]]:
    pendientes: List[Tuple[Path, str]] = []
    for ag in AGENCIAS:
        carpeta_ag = base_path / ag
        if not carpeta_ag.is_dir():
            continue
        for patron in ("*.xls", "*.xlsx"):
            for p in carpeta_ag.glob(patron):
                if p.name.startswith("~$"):
                    continue
                pendientes.append((p, ag))
    return pendientes

def obtener_dirs_salida(root: Path, agencia: str, fecha_str: str) -> Tuple[Path, Path]:
    """
    Devuelve (dir_procesado, dir_consolidado) para una agencia en la fecha indicada.
    Ambos son la MISMA carpeta:
        PROCESADO/AAAA-MM-DD/AGENCIA
    donde se guardan:
      - el archivo original (movido)
      - el archivo *_PROCESADO.*
    Eso se hace para poder verificar en caso de se necesite si el script 
    est√° capturando correctamente los datos o si hubo alg√∫n error
    """
    dir_trabajo = root / "PROCESADO" / fecha_str / agencia
    dir_trabajo.mkdir(parents=True, exist_ok=True)
    return dir_trabajo, dir_trabajo

def procesar_archivo(fecha_ejecucion: datetime, path: Path, agencia: str, base_path: Path) -> None:
    """
    Despacha seg√∫n el prefijo del nombre y mueve el original a
    PROCESADO/AAAA-MM-DD/AGENCIA junto con el *_PROCESADO.
    """
    fecha_str = fecha_ejecucion.strftime("%Y-%m-%d")
    dir_entrada = str(path.parent)

    # üëâ ac√° tiene que ir base_path, no root
    dir_procesado, dir_consolidado = obtener_dirs_salida(base_path, agencia, fecha_str)

    filename = path.name
    fname_upper = filename.upper()
    fname_norm = fname_upper.replace(" ", "_")

    try:
        salida: Optional[str] = None

        if fname_norm.startswith('EC_ATM'):
            salida = get_ec_atm(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        elif fname_norm.startswith('EC_BANCO') or fname_norm.startswith('EC_BCO'):
            salida = get_ec_banco(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        elif fname_norm.startswith('EC_BULTOS_ATM'):
            salida = get_ec_bultos_atm(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        elif fname_norm.startswith('EC_BULTOS_BCO') or fname_norm.startswith('EC_BULTOS_BANCO'):
            salida = get_ec_bultos_bco(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        elif fname_norm.startswith('INV_BILLETES_ATM') or fname_norm.startswith('INV_ATM'):
            salida = get_inv_atm(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        elif (fname_norm.startswith('INV_BILLETES_BANCO') or
              fname_norm.startswith('INV_BCO') or
              fname_norm.startswith('INV_BANCO')):
            salida = get_inv_bco(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        else:
            logger.info(f'[SKIP] No se reconoce tipo para: {filename}')
            return

        if salida is None:
            logger.info(f'[WARN] {filename}: parser no devolvi√≥ registros (salida=None). No se mueve el archivo.')
            return

        # Mover archivo original a PROCESADO/fecha/agencia
        dst = dir_procesado / filename
        shutil.move(str(path), str(dst))
        logger.info(f'[MOVE] {filename} -> {dst}')

    except Exception as e:
        logger.error(f'[ERROR] Procesando {filename}: {e}')

def generar_consolidados(base_path: Path, fecha_ejecucion: datetime) -> None:
    """
    Lee todos los *_PROCESADO.* de PROCESADO/AAAA-MM-DD/AGENCIA/
    y genera los consolidados finales en:

        CONSOLIDADO/AAAA-MM-DD/
            PROSEGUR_BULTOSATM.csv
            PROSEGUR_BULTOSBANCO.csv
            PROSEGUR_EFECTATM.csv
            PROSEGUR_EFECTBANCO.csv
            PROSEGUR_INVENTARIO_ATM.csv
            PROSEGUR_INVENTARIO_BCO.csv
    """
    fecha_str = fecha_ejecucion.strftime("%Y-%m-%d")
    base_proc = base_path / "PROCESADO" / fecha_str
    consol_dir = base_path / "CONSOLIDADO" / fecha_str
    consol_dir.mkdir(parents=True, exist_ok=True)

    if not base_proc.exists():
        logger.info(f"[CONSOLIDADO] No existe la carpeta {base_proc}, no se generan consolidados.")
        return

    # Acumuladores por tipo
    data = {
        "EFECT_ATM": [],
        "EFECT_BCO": [],
        "BULTOS_ATM": [],
        "BULTOS_BCO": [],
        "INV_ATM": [],
        "INV_BCO": [],
    }

    # Recorremos PROCESADO/fecha/AGENCIA y juntamos todos los *_PROCESADO
    for ag in AGENCIAS:
        ag_dir = base_proc / ag
        if not ag_dir.exists():
            continue

        # leemos todos los xlsx/csv procesados
        for pattern in ("*.xlsx", "*.csv"):
            for f in ag_dir.glob(pattern):
                fname_up = f.name.upper()
                # S√≥lo archivos procesados
                if "_PROCESADO" not in fname_up:
                    continue

                try:
                    if f.suffix.lower() == ".xlsx":
                        df = pd.read_excel(f)
                    else:
                        df = pd.read_csv(f)
                except Exception as e:
                    logger.info(f"[CONSOLIDADO] No se pudo leer '{f}': {e}")
                    continue

                # Clasificaci√≥n por tipo seg√∫n nombre
                if "EC_ATM" in fname_up:
                    data["EFECT_ATM"].append(df)
                elif "EC_BANCO" in fname_up or "EC_BCO" in fname_up:
                    data["EFECT_BCO"].append(df)
                elif "EC_BULTOS_ATM" in fname_up:
                    data["BULTOS_ATM"].append(df)
                elif "EC_BULTOS_BCO" in fname_up or "EC_BULTOS_BANCO" in fname_up:
                    data["BULTOS_BCO"].append(df)
                elif "INV_BILLETES_ATM" in fname_up or "INV_ATM" in fname_up:
                    data["INV_ATM"].append(df)
                elif ("INV_BILLETES_BANCO" in fname_up or
                      "INV_BCO" in fname_up or
                      "INV_BANCO" in fname_up):
                    data["INV_BCO"].append(df)

    # === EFECTIVO ATM ===
    if data["EFECT_ATM"]:
        df_efect_atm = pd.concat(data["EFECT_ATM"], ignore_index=True)

        # Normalizar agencia
        if "AGENCIA" in df_efect_atm.columns:
            df_efect_atm["AGENCIA"] = df_efect_atm["AGENCIA"].apply(_normaliza_agencia)

        # Si por error arrastramos HOJA_ORIGEN, la quitamos
        if "HOJA_ORIGEN" in df_efect_atm.columns:
            df_efect_atm = df_efect_atm.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_EFECTATM.csv"
        df_efect_atm.to_csv(out_path, index=False, encoding="utf-8-sig", sep=';')
        logger.info(f"[CONSOLIDADO] PROSEGUR_EFECTATM.csv: {df_efect_atm.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_EFECTATM.csv")

    # === EFECTIVO BANCO ===
    if data["EFECT_BCO"]:
        df_efect_bco = pd.concat(data["EFECT_BCO"], ignore_index=True)

        if "AGENCIA" in df_efect_bco.columns:
            df_efect_bco["AGENCIA"] = df_efect_bco["AGENCIA"].apply(_normaliza_agencia)

        # Este s√≠ suele llevar HOJA_ORIGEN, pero lo sacamos en el consolidado final
        if "HOJA_ORIGEN" in df_efect_bco.columns:
            df_efect_bco = df_efect_bco.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_EFECTBANCO.csv"
        df_efect_bco.to_csv(out_path, index=False, encoding="utf-8-sig", sep=';')
        logger.info(f"[CONSOLIDADO] PROSEGUR_EFECTBANCO.csv: {df_efect_bco.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_EFECTBANCO.csv")

    # === BULTOS ATM ===
    if data["BULTOS_ATM"]:
        df_bultos_atm = pd.concat(data["BULTOS_ATM"], ignore_index=True)

        # Normalizar agencia
        if "AGENCIA" in df_bultos_atm.columns:
            df_bultos_atm["AGENCIA"] = df_bultos_atm["AGENCIA"].apply(_normaliza_agencia)

        # Normalizar moneda por si acaso
        if "MONEDA" in df_bultos_atm.columns:
            df_bultos_atm["MONEDA"] = df_bultos_atm["MONEDA"].apply(_normaliza_moneda_iso)

        # Construir una sola columna SALDO_ANTERIOR en funci√≥n de MONEDA
        if "SALDO_ANTERIOR" not in df_bultos_atm.columns:
            df_bultos_atm["SALDO_ANTERIOR"] = 0

        if "SALDO_ANTERIOR_PYG" in df_bultos_atm.columns or "SALDO_ANTERIOR_USD" in df_bultos_atm.columns:
            # Para filas en PYG
            df_bultos_atm.loc[df_bultos_atm["MONEDA"] == "PYG", "SALDO_ANTERIOR"] = \
                df_bultos_atm.loc[df_bultos_atm["MONEDA"] == "PYG", "SALDO_ANTERIOR_PYG"]

            # Para filas en USD
            df_bultos_atm.loc[df_bultos_atm["MONEDA"] == "USD", "SALDO_ANTERIOR"] = \
                df_bultos_atm.loc[df_bultos_atm["MONEDA"] == "USD", "SALDO_ANTERIOR_USD"]

            # Ya no necesitamos las columnas separadas
            df_bultos_atm = df_bultos_atm.drop(columns=["SALDO_ANTERIOR_PYG", "SALDO_ANTERIOR_USD"])

        # No queremos HOJA_ORIGEN en el consolidado final
        if "HOJA_ORIGEN" in df_bultos_atm.columns:
            df_bultos_atm = df_bultos_atm.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_BULTOSATM.csv"
        df_bultos_atm.to_csv(out_path, index=False, encoding="utf-8-sig", sep=';')
        logger.info(f"[CONSOLIDADO] PROSEGUR_BULTOSATM.csv: {df_bultos_atm.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_BULTOSATM.csv")


    # === BULTOS BANCO ===
    if data["BULTOS_BCO"]:
        df_bultos_bco = pd.concat(data["BULTOS_BCO"], ignore_index=True)

        # Normalizar agencia
        if "AGENCIA" in df_bultos_bco.columns:
            df_bultos_bco["AGENCIA"] = df_bultos_bco["AGENCIA"].apply(_normaliza_agencia)

        # Si por alg√∫n motivo llegan columnas separadas de saldo, las unificamos
        if "SALDO_ANTERIOR" not in df_bultos_bco.columns:
            if ("SALDO_ANTERIOR_PYG" in df_bultos_bco.columns or
                "SALDO_ANTERIOR_USD" in df_bultos_bco.columns):

                def _elige_saldo(row):
                    mon = str(row.get("MONEDA", "")).upper()
                    if mon == "PYG" and "SALDO_ANTERIOR_PYG" in row:
                        return row.get("SALDO_ANTERIOR_PYG", 0)
                    if mon == "USD" and "SALDO_ANTERIOR_USD" in row:
                        return row.get("SALDO_ANTERIOR_USD", 0)
                    # fallback: primera columna de saldo que exista
                    for c in ("SALDO_ANTERIOR_PYG", "SALDO_ANTERIOR_USD"):
                        if c in row and not pd.isna(row[c]):
                            return row[c]
                    return 0

                df_bultos_bco["SALDO_ANTERIOR"] = df_bultos_bco.apply(_elige_saldo, axis=1)

        # En cualquier caso, nos quedamos solo con SALDO_ANTERIOR
        for col in ["SALDO_ANTERIOR_PYG", "SALDO_ANTERIOR_USD"]:
            if col in df_bultos_bco.columns:
                df_bultos_bco = df_bultos_bco.drop(columns=[col])

        # Quitar HOJA_ORIGEN si existe
        if "HOJA_ORIGEN" in df_bultos_bco.columns:
            df_bultos_bco = df_bultos_bco.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_BULTOSBANCO.csv"
        df_bultos_bco.to_csv(out_path, index=False, encoding="utf-8-sig", sep=';')
        logger.info(f"[CONSOLIDADO] BULTOS_BCO -> {out_path}")

    # === INVENTARIO ATM ===
    if data["INV_ATM"]:
        df_inv_atm = pd.concat(data["INV_ATM"], ignore_index=True)

        if "AGENCIA" in df_inv_atm.columns:
            df_inv_atm["AGENCIA"] = df_inv_atm["AGENCIA"].apply(_normaliza_agencia)

        if "HOJA_ORIGEN" in df_inv_atm.columns:
            df_inv_atm = df_inv_atm.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_INVENTARIO_ATM.csv"
        df_inv_atm.to_csv(out_path, index=False, encoding="utf-8-sig", sep=';')
        logger.info(f"[CONSOLIDADO] PROSEGUR_INVENTARIO_ATM.csv: {df_inv_atm.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_INVENTARIO_ATM.csv")

    # === INVENTARIO BANCO ===
    if data["INV_BCO"]:
        df_inv_bco = pd.concat(data["INV_BCO"], ignore_index=True)

        if "AGENCIA" in df_inv_bco.columns:
            df_inv_bco["AGENCIA"] = df_inv_bco["AGENCIA"].apply(_normaliza_agencia)

        if "HOJA_ORIGEN" in df_inv_bco.columns:
            df_inv_bco = df_inv_bco.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_INVENTARIO_BCO.csv"
        df_inv_bco.to_csv(out_path, index=False, encoding="utf-8-sig", sep=';')
        logger.info(f"[CONSOLIDADO] PROSEGUR_INVENTARIO_BCO.csv: {df_inv_bco.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_INVENTARIO_BCO.csv")


########################################
################ MAIN ##################
########################################

def main():
    # Ya no llamamos resolve_root_prosegur, usamos root_path global
    base_path = root_path

    fecha_ejecucion = datetime.now()
    fecha_str = fecha_ejecucion.strftime("%Y-%m-%d")

    # Carpeta CONSOLIDADO/AAAA-MM-DD y log PROSEGUR.txt dentro
    consol_dir = base_path / "CONSOLIDADO" / fecha_str
    consol_dir.mkdir(parents=True, exist_ok=True)

    logger.add(
        str(consol_dir / "PROSEGUR.txt"),
        level="INFO",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
    )

    logger.info("=" * 50)
    logger.info(f"[INICIO] Consolidado PROSEGUR unificado - {fecha_ejecucion:%Y-%m-%d %H:%M:%S}")
    logger.info(f"ROOT_PATH = {base_path}")

    pendientes = colectar_pendientes(base_path)
    if not pendientes:
        logger.info("No se encontraron archivos pendientes en subcarpetas de agencias.")
    else:
        logger.info(f"Archivos pendientes encontrados: {len(pendientes)}")
        for path, agencia in pendientes:
            logger.info(f"Procesando {path.name} (agencia {agencia})...")
            procesar_archivo(fecha_ejecucion, path, agencia, base_path)

    generar_consolidados(base_path, fecha_ejecucion)

    logger.info("[FIN] Consolidado PROSEGUR unificado")


if __name__ == "__main__":
    main()
