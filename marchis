
# === CONSOLIDADO PROSEGUR UNIFICADO (sin dependencias externas) ===
import os
import re
import shutil
import unicodedata
from datetime import datetime
from pathlib import Path
from typing import Optional, Union, List, Dict, Any, Tuple

import numpy as np
import pandas as pd

from loguru import logger
import sys

# Configuración básica del logger
logger.remove()
logger.add(sys.stdout, level="INFO", format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}")

# Agencias esperadas como subcarpetas dentro del ROOT (carpeta PROSEGUR)
AGENCIAS = ['ASU', 'CDE', 'CNC', 'ENC', 'OVD']


def _strip_accents(s: str) -> str:
    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')


def _first_non_empty_after(row_vals: List[str], start_idx: int) -> Optional[int]:
    """Devuelve el índice de la primera celda no vacía a partir de start_idx+1, o None."""
    for i in range(start_idx + 1, len(row_vals)):
        if str(row_vals[i]).strip() != '':
            return i
    return None


def _get_cell(row_vals: List[str], idx: Optional[int], default: str = '') -> str:
    if idx is None or idx >= len(row_vals):
        return default
    v = str(row_vals[idx]).strip()
    return v if v != '' else default


def _only_digits(s: str) -> str:
    """Devuelve solo dígitos (para recibo), sin cortar ceros a la izquierda."""
    return ''.join(ch for ch in str(s) if ch.isdigit())

def _to_int(s: Any) -> int:
    """
    Convierte '64.849.637.000' -> 64849637000, '2.409,00' -> 2409, '0,00' -> 0.
    Si no puede, devuelve 0.
    """
    if s is None:
        return 0
    t = str(s).strip()
    if t == '':
        return 0
    # normalizar coma decimal a punto y quitar separadores de miles
    t = t.replace('.', '').replace(',', '.')
    try:
        return int(float(t))
    except Exception:
        # fallback: solo dígitos
        digits = ''.join(ch for ch in t if ch.isdigit())
        return int(digits) if digits else 0

def _extraer_saldos_desde_fila(celdas: List[Any], max_take: int = 6) -> List[int]:
    """
    Dada una fila (lista de celdas), localiza la posición de 'SALDO ANTERIOR'
    (soportando que venga en una sola celda o separada 'SALDO'/'ANTERIOR')
    y devuelve hasta max_take valores numéricos (int) a su derecha.
    Si una celda a la derecha no es numérica (ej. 'TOTAL', etc.), se devuelve 0
    para mantener la posición.
    """
    textos = [_txt(c) for c in celdas]
    ups = [_strip_accents(t).upper() for t in textos]

    idx = None

    # 1) Intentar encontrar "SALDO ANTERIOR" en una sola celda
    for i, u in enumerate(ups):
        if "SALDO ANTERIOR" in u:
            idx = i
            break

    # 2) Si no, intentar "SALDO" seguido de "ANTERIOR" en la siguiente celda
    if idx is None:
        for i in range(len(ups) - 1):
            if "SALDO" in ups[i] and "ANTERIOR" in ups[i + 1]:
                idx = i + 1  # tomamos la celda que contiene "ANTERIOR" como referencia
                break

    # 3) Fallback: primera celda que contenga "SALDO" o "ANTERIOR"
    if idx is None:
        for i, u in enumerate(ups):
            if "SALDO" in u or "ANTERIOR" in u:
                idx = i
                break

    if idx is None:
        return []

    # 4) Recorrer hacia la derecha y tomar hasta max_take valores
    res: List[int] = []
    j = idx + 1
    while j < len(textos) and len(res) < max_take:
        v = textos[j].strip()
        if v != "":
            n = _to_int(v)
            # si no se puede convertir, dejamos 0, pero conservamos la posición
            res.append(n if n is not None else 0)
        j += 1

    return res



def _ordenar_y_renombrar_columnas_ec(df: pd.DataFrame) -> pd.DataFrame:
    """Normaliza encabezados y asegura el orden final esperado para EC_*."""
    df.columns = [str(c).replace(' ', '_').upper() for c in df.columns]
    rename_map = {'FECHA_OPER': 'FECHA', 'MOTIVO MOVIMIENTO': 'MOTIVO_MOVIMIENTO'}
    df = df.rename(columns=rename_map)
    orden_final = [
        'FECHA',
        'SUCURSAL',
        'RECIBO',
        'BULTOS',
        'GUARANIES',
        'DOLARES',
        'ING_EGR',
        'CLASIFICACION',
        'FECHA_ARCHIVO',
        'MOTIVO_MOVIMIENTO',
        'AGENCIA',
        'SALDO_ANTERIOR_PYG',
        'SALDO_ANTERIOR_USD',
    ]
    for col in orden_final:
        if col not in df.columns:
            # Para saldos, por defecto 0; para el resto, cadena vacía
            if col.startswith('SALDO_ANTERIOR'):
                df[col] = 0
            else:
                df[col] = ''
    return df[orden_final]


def encontrar_fecha(texto: str) -> Optional[str]:
    """Encuentra dd/mm/yyyy en un texto; devuelve la primera coincidencia o None."""
    if not texto:
        return None
    m = re.search(r'(\d{1,2}/\d{1,2}/\d{4})', texto)
    return m.group(1) if m else None


def encontrar_fecha_en_columna(serie: pd.Series) -> Optional[str]:
    """Busca la primera fecha válida dd/mm/yyyy en una serie/columna libre."""
    for val in serie.astype(str).tolist():
        f = encontrar_fecha(val)
        if f:
            return f
    return None


def get_agencia(linea_cabecera: str) -> str:
    """
    Extrae la agencia de una línea tipo 'PROSEGUR PARAGUAY S.A. (SUCURSAL: Ciudad del Este)'.
    Si no encuentra, devuelve ''.
    """
    if not linea_cabecera:
        return ''
    m = re.search(r'SUCURSAL:\s*([^)]+)\)', linea_cabecera, flags=re.IGNORECASE)
    return m.group(1).strip() if m else ''


def _normaliza_moneda(token: str) -> str:
    """Normaliza a: GUARANIES, DOLARES, EUROS, REALES, PESOS."""
    t = _strip_accents(str(token)).upper()
    if 'GUARANI' in t:
        return 'GUARANIES'
    if 'DOLAR' in t or 'DOLARE' in t or 'USD' in t:
        return 'DOLARES'
    if 'EURO' in t or 'EUR' in t:
        return 'EUROS'
    if 'REAL' in t or 'BRL' in t:
        return 'REALES'
    if 'PESO' in t or 'ARS' in t:
        return 'PESOS'
    return t

def _normaliza_moneda_iso(token: str) -> str:
    t = _strip_accents(str(token)).upper().strip()
    if any(k in t for k in ['PYG', 'GS', 'G$', '₲', 'GUARANI']):
        return 'PYG'
    if any(k in t for k in ['USD', 'US$', 'U$S', 'DOLAR', 'DOLARES']):
        return 'USD'
    if any(k in t for k in ['EUR', '€', 'EURO']):
        return 'EUR'
    if any(k in t for k in ['BRL', 'R$', 'REAL']):
        return 'BRL'
    if any(k in t for k in ['ARS', 'PESO']):
        return 'ARS'
    return t

def _normaliza_agencia(s: str) -> str:
    t = _strip_accents(str(s)).upper()
    if 'CIUDAD DEL ESTE' in t or t == 'CDE':
        return 'CDE'
    if 'ASUNCION' in t or t == 'ASU':
        return 'ASU'
    if 'CONCEPCION' in t or t == 'CON':
        return 'CON'
    if 'ENCARNACION' in t or t == 'ENC':
        return 'ENC'
    if 'OVIEDO' in t or t == 'OVD':
        return 'OVD'
    # deja como estaba si no matchea ninguna conocida
    return t if len(t) <= 5 else t[:3]

def _guess_currency_from_sheet_name(sheet_name: str) -> str:
    """Intenta inferir la moneda a partir del nombre de la hoja."""
    n = _strip_accents(str(sheet_name)).upper()
    if any(k in n for k in ['USD', 'DOLAR', 'DOLARES']):
        return 'DOLARES'
    if any(k in n for k in ['EUR', 'EURO', 'EUROS']):
        return 'EUROS'
    if any(k in n for k in ['BRL', 'REAL', 'REALES']):
        return 'REALES'
    if any(k in n for k in ['ARS', 'PESO', 'PESOS', 'ARG']):
        return 'PESOS'
    if any(k in n for k in ['PYG', 'GUARANI']):
        return 'GUARANIES'
    return ''  # desconocido


def _leer_hojas_excel(path_entrada: str, sheet_name=None) -> dict:
    """
    Devuelve un dict {nombre_hoja: DataFrame} según el parámetro.
    None -> todas las hojas; int/str -> una sola; lista -> solo esas.
    """
    if sheet_name is None:
        return pd.read_excel(path_entrada, sheet_name=None, header=None, dtype=str)
    if isinstance(sheet_name, (list, tuple)):
        return pd.read_excel(path_entrada, sheet_name=list(sheet_name), header=None, dtype=str)
    # un solo nombre/índice
    df = pd.read_excel(path_entrada, sheet_name=sheet_name, header=None, dtype=str)
    return {sheet_name: df}


def _ordenar_y_renombrar_columnas_ec_banco(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).replace(' ', '_').upper() for c in df.columns]
    df = df.rename(columns={
        'FECHA_OPER': 'FECHA',
        'MONTO': 'IMPORTE',
        'MOTIVO MOVIMIENTO': 'MOTIVO_MOVIMIENTO',
    })
    orden_final = [
        'FECHA', 'SUCURSAL', 'RECIBO', 'BULTOS', 'IMPORTE', 'MONEDA',
        'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
        'AGENCIA', 'SALDO_ANTERIOR'
    ]
    for col in orden_final:
        if col not in df.columns:
            df[col] = ''
    return df[orden_final]


def _is_zero_like(s: str) -> bool:
    """True si el string representa 0 (con o sin separadores)."""
    t = str(s).replace(',', '').replace('.', '').strip()
    return t == '' or t == '0'


def _ordenar_y_renombrar_columnas_bultos(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).replace(' ', '_').upper() for c in df.columns]
    df = df.rename(columns={'FECHA_OPER': 'FECHA'})
    orden_final = [
        'FECHA', 'SUCURSAL', 'RECIBO', 'BULTOS', 'MONEDA', 'IMPORTE',
        'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
        'AGENCIA', 'SALDO_ANTERIOR_PYG', 'SALDO_ANTERIOR_USD', 'SALDO_ANTERIOR', 'HOJA_ORIGEN'
    ]
    for col in orden_final:
        if col not in df.columns:
            df[col] = 0 if col.startswith('SALDO_ANTERIOR') else ''
    return df[orden_final]


def _ordenar_y_renombrar_columnas_bultos_bco(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).replace(' ', '_').upper() for c in df.columns]
    df = df.rename(columns={'FECHA_OPER': 'FECHA'})
    orden_final = [
        'FECHA', 'SUCURSAL', 'RECIBO', 'BULTOS', 'MONEDA', 'IMPORTE',
        'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
        'AGENCIA', 'SALDO_ANTERIOR'
    ]
    for col in orden_final:
        if col not in df.columns:
            df[col] = ''
    return df[orden_final]

def _normaliza_moneda_iso(token: str) -> str:
    """
    Devuelve códigos ISO comunes: PYG, USD, EUR, BRL, ARS.
    Tolera variantes locales (Gs, U$S, US$, R$, €, 'guaraníes', etc).
    """
    t = _strip_accents(str(token)).upper().strip()

    # Casos específicos primero (evitar colisiones con '$')
    if any(k in t for k in ['PYG', 'GS', 'G$', 'G ', '₲', 'GUARANI', 'GUARANIES']):
        return 'PYG'
    if any(k in t for k in ['USD', 'US$', 'U$S', 'DOLAR', 'DOLARES']):
        return 'USD'
    if any(k in t for k in ['EUR', '€', 'EURO', 'EUROS']):
        return 'EUR'
    if any(k in t for k in ['BRL', 'R$', 'REAL', 'REALES']):
        return 'BRL'
    if any(k in t for k in ['ARS', 'PESO', 'PESOS', 'ARG']):
        return 'ARS'

    # Heurística: si aparece '$' y no se detectó arriba, preferimos USD
    if '$' in t:
        return 'USD'
    return t  # fallback (por si usan un código no previsto)


def _txt(x) -> str:
    return "" if pd.isna(x) else str(x).strip()


def _upper(x) -> str:
    return re.sub(r"\s+", " ", _txt(x)).upper()


def _to_int(x) -> Optional[int]:
    """Convierte valores tipo '3.000', '3,000', '3000.0' a int. Devuelve None si no es número."""
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return None
    if isinstance(x, (int, float)) and not isinstance(x, bool):
        try:
            return int(round(float(x)))
        except Exception:
            pass
    s = _txt(x).replace("\xa0", " ").strip()
    if s == "":
        return None
    if re.fullmatch(r"\d+\.\d+", s):
        return int(float(s))
    digits = re.sub(r"[^\d\-]", "", s)
    if digits in ("", "-", "--"):
        return None
    try:
        return int(digits)
    except Exception:
        return None
    
def _extraer_saldos_desde_fila(strip_cells: List[str], max_take: int = 6) -> List[int]:
    """
    Busca la celda que contiene 'SALDO ANTERIOR' (acentos/espacios tolerados)
    y devuelve hasta max_take valores numéricos no vacíos a su derecha, ya convertidos a int.
    """
    up = [_strip_accents(c).upper() for c in strip_cells]
    try:
        idx = next(i for i, c in enumerate(up) if 'SALDO ANTERIOR' in c)
    except StopIteration:
        return []

    out: List[int] = []
    j = idx + 1
    while j < len(strip_cells) and len(out) < max_take:
        v = str(strip_cells[j]).strip()
        if v != '':
            out.append(_to_int(v) or 0)
        j += 1
    return out


def get_ec_atm(fecha_ejecucion: datetime,
               filename: str,
               dir_entrada: str,
               dir_consolidado: str,
               sheet_name: Union[int, str] = 0) -> Optional[str]:
    """
    Procesa un archivo EC_ATM*.* desde dir_entrada y genera un Excel procesado en dir_consolidado.
    Devuelve la ruta de salida o None si no se obtuvieron registros.
    """
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    # Lectura cruda (sin encabezados) y normalización básica
    df_raw = pd.read_excel(path_entrada, sheet_name=sheet_name, header=None, dtype=str).fillna('')

    saldo_ant_usd: Optional[int] = 0
    saldo_ant_pyg: Optional[int] = 0

    rx_fecha_cell = re.compile(r'^\s*\d{1,2}/\d{1,2}/\d{4}\s*$')
    rx_totales = re.compile(r'\b(TOTAL|SUBTOTAL)\b', re.IGNORECASE)

    agencia = ''
    fecha_archivo = ''
    clasificacion = 'ATM'
    ing_egr = ''  # IN / OUT
    motivo_actual = ''

    registros: List[Dict[str, str]] = []

    for _, row in df_raw.iterrows():
        cells = [str(x) if x is not None else '' for x in row.values]
        strip_cells = [c.strip() for c in cells]
        line_join = ' '.join([c for c in strip_cells if c])
        if not line_join:
            continue

        upper_join = _strip_accents(line_join).upper()

        # Cabeceras / metadatos
        if 'PROSEGUR PARAGUAY S.A.' in upper_join:
            # e.g. "PROSEGUR PARAGUAY S.A. (SUCURSAL: Ciudad del Este)"
            ag = get_agencia(line_join)
            if ag:
                agencia = ag
            continue

        if 'ESTADO DE CUENTA DE' in upper_join:
            m_f = re.search(r'AL:\s*(\d{1,2}/\d{1,2}/\d{4})', line_join, flags=re.IGNORECASE)
            if m_f:
                fecha_archivo = m_f.group(1)
            continue

        if upper_join == 'INGRESOS':
            ing_egr = 'IN'
            motivo_actual = ''
            continue

        if upper_join == 'EGRESOS':
            ing_egr = 'OUT'
            motivo_actual = ''
            continue

        if 'INFORME DE PROCESOS' in upper_join:
            # fin del bloque útil
            break

        if rx_totales.search(line_join):
            # ignorar líneas de totales/subtotales
            continue

        # Buscar fila de "Saldo Anterior" (1º USD, 2º PYG)
        if 'SALDO ANTERIOR' in upper_join and not (saldo_ant_usd or saldo_ant_pyg):
            valores = _extraer_saldos_desde_fila(strip_cells)
            # EC_ATM: primer valor = USD, segundo = PYG
            if len(valores) >= 1 and valores[0] is not None:
                saldo_ant_usd = valores[0]
            if len(valores) >= 2 and valores[1] is not None:
                saldo_ant_pyg = valores[1]
            # Esta fila no es detalle de movimiento
            continue

        # Detectar si la fila es "motivo" o "detalle"
        date_idx = next((i for i, c in enumerate(strip_cells) if rx_fecha_cell.match(c)), None)

        if ing_egr and date_idx is None:
            # Fila de MOTIVO (texto)
            motivo_actual = line_join.strip()
            continue

        # Fila de DETALLE (tiene una celda fecha)
        if ing_egr and motivo_actual and date_idx is not None:
            fecha_oper = strip_cells[date_idx]

            # SUCURSAL: primera celda no vacía después de la fecha
            suc_idx = _first_non_empty_after(strip_cells, date_idx)
            sucursal = _get_cell(strip_cells, suc_idx, default='')

            # RECIBO: primera no vacía después de SUCURSAL (no parseamos número del texto de sucursal)
            rec_idx = _first_non_empty_after(strip_cells, suc_idx) if suc_idx is not None else None
            recibo_raw = _get_cell(strip_cells, rec_idx, default='')
            recibo_digits = _only_digits(recibo_raw)
            recibo = recibo_digits if recibo_digits != '' else recibo_raw

            # BULTOS
            bul_idx = _first_non_empty_after(strip_cells, rec_idx) if rec_idx is not None else None
            bultos = _get_cell(strip_cells, bul_idx, default='')

            # GUARANIES
            gua_idx = _first_non_empty_after(strip_cells, bul_idx) if bul_idx is not None else None
            guaranies = _get_cell(strip_cells, gua_idx, default='0') or '0'

            # DOLARES
            usd_idx = _first_non_empty_after(strip_cells, gua_idx) if gua_idx is not None else None
            dolares = _get_cell(strip_cells, usd_idx, default='0') or '0'

            registros.append({
                'FECHA_OPER': fecha_oper,
                'SUCURSAL': sucursal,
                'RECIBO': recibo,
                'BULTOS': bultos,
                'GUARANIES': guaranies,
                'DOLARES': dolares,
                'ING_EGR': ing_egr,
                'CLASIFICACION': clasificacion,
                'FECHA_ARCHIVO': fecha_archivo,
                'MOTIVO_MOVIMIENTO': motivo_actual,
                'AGENCIA': agencia,
                'SALDO_ANTERIOR_PYG': saldo_ant_pyg,
                'SALDO_ANTERIOR_USD': saldo_ant_usd,
            })

    # DataFrame final ordenado
    df_out = pd.DataFrame(registros)
    if df_out.empty:
        # Creamos estructura vacía para no romper el flujo, pero avisamos
        df_out = pd.DataFrame(columns=[
            'FECHA_OPER', 'SUCURSAL', 'RECIBO', 'BULTOS', 'GUARANIES', 'DOLARES',
            'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO', 'AGENCIA', 'SALDO_ANTERIOR_PYG', 'SALDO_ANTERIOR_USD'
        ])
        logger.error(f'[EC_ATM] {filename}: No se detectaron registros válidos.')

    df_out = _ordenar_y_renombrar_columnas_ec(df_out)
    df_out.to_excel(path_salida, index=False)
    logger.info(f'[EC_ATM] Guardado: {path_salida}')
    return path_salida

def get_ec_banco(fecha_ejecucion: datetime,
                 filename: str,
                 dir_entrada: str,
                 dir_consolidado: str,
                 sheet_name=None) -> Optional[str]:
    """
    Procesa un archivo EC_BANCO*.xlsx desde dir_entrada y genera un Excel procesado en dir_consolidado.
    Usa IMPORTE + MONEDA (una sola columna de monto con su moneda).
    Devuelve la ruta de salida o None si no se obtuvieron registros.
    """
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    hojas = _leer_hojas_excel(path_entrada, sheet_name=sheet_name)

    # Regex útiles
    rx_fecha_linea = re.compile(r'^\s*(\d{1,2}/\d{1,2}/\d{4})\b')
    rx_totales = re.compile(r'\b(TOTAL|SUBTOTAL)\b', re.IGNORECASE)
    rx_moneda = re.compile(r'\b(GUARAN[IÍ]ES|D[ÓO]LARES|EUROS?|REALES?|PESOS?)\b', re.IGNORECASE)

    mapa_clasif = {
        'BANCO': 'BCO',
        'ATM': 'ATM',
        'BULTOS DE BANCO': 'BULTO BCO',
        'BULTOS DE ATM': 'BULTO ATM',
    }

    registros = []

    for nombre_hoja, df in hojas.items():
        df = df.fillna('')

        agencia = ''
        fecha_archivo = ''
        clasificacion = ''
        ing_egr = ''           # IN / OUT
        motivo_actual = ''

        # saldo anterior por HOJA (moneda)
        saldo_anterior_hoja = 0

        # Moneda por defecto: intento por nombre de hoja; si no, GUARANIES
        moneda_actual = _guess_currency_from_sheet_name(nombre_hoja) or 'GUARANIES'

        for _, row in df.iterrows():
            row_vals = [str(x).strip() for x in row.values]
            linea = ' '.join([v for v in row_vals if v])
            if not linea:
                continue

            linea_up = _strip_accents(linea).upper()

            # --- SALDO ANTERIOR por hoja ---
            if 'SALDO ANTERIOR' in linea_up and not saldo_anterior_hoja:
                vals = _extraer_saldos_desde_fila(row_vals)
                if vals:
                    # En EC_BANCO: tomamos el primer valor no vacío a la derecha
                    saldo_anterior_hoja = vals[0] or 0
                continue

            # Agencia
            if 'PROSEGUR PARAGUAY S.A.' in linea_up:
                m = re.search(r'SUCURSAL:\s*([^)]+)\)', linea, flags=re.IGNORECASE)
                if m:
                    agencia = m.group(1).strip()
                continue

            # Clasificación y fecha de archivo
            if 'ESTADO DE CUENTA DE' in linea_up:
                m_tipo = re.search(r'ESTADO DE CUENTA DE\s+(.*?)\s+AL:', linea, flags=re.IGNORECASE)
                if m_tipo:
                    texto = m_tipo.group(1).strip()
                    texto_norm = _strip_accents(texto).upper()
                    clasificacion = mapa_clasif.get(texto_norm, texto.strip())
                m_f = re.search(r'AL:\s*(\d{1,2}/\d{1,2}/\d{4})', linea, flags=re.IGNORECASE)
                if m_f:
                    fecha_archivo = m_f.group(1)
                continue

            # Secciones IN/OUT
            if linea_up == 'INGRESOS':
                ing_egr = 'IN'
                motivo_actual = ''
                continue
            if linea_up == 'EGRESOS':
                ing_egr = 'OUT'
                motivo_actual = ''
                continue

            # Fin del bloque útil
            if 'INFORME DE PROCESOS' in linea_up:
                break

            # Saltar totales/subtotales
            if rx_totales.search(linea):
                continue

            # Detectar/actualizar moneda en encabezados
            m_moneda = rx_moneda.search(linea)
            if m_moneda:
                moneda_actual = _normaliza_moneda_iso(m_moneda.group(1))
                continue

            # Encabezado de motivo (línea no-fecha dentro de IN/OUT)
            if ing_egr and not rx_fecha_linea.match(linea):
                motivo_actual = linea.strip()
                continue

            # Fila de detalle (comienza con fecha)
            m_date = rx_fecha_linea.match(linea)
            if ing_egr and motivo_actual and m_date:
                parts = linea.split()
                if not parts:
                    continue

                fecha_oper = parts[0]

                # Índice del recibo (primer número con al menos 6 dígitos)
                idx_rec = next(
                    (i for i, p in enumerate(parts[1:], 1) if re.fullmatch(r'\d{6,}', p)),
                    None
                )
                if idx_rec is None:
                    # si no hay recibo claro, omitimos para evitar falsos positivos
                    continue

                sucursal = ' '.join(parts[1:idx_rec]).strip()
                recibo = parts[idx_rec]
                bultos = parts[idx_rec + 1] if idx_rec + 1 < len(parts) else ''
                importe = parts[idx_rec + 2] if idx_rec + 2 < len(parts) else ''

                registros.append({
                    'HOJA_ORIGEN': nombre_hoja,
                    'AGENCIA': agencia,
                    'FECHA_ARCHIVO': fecha_archivo,
                    'ING_EGR': ing_egr,
                    'CLASIFICACION': clasificacion,
                    'MOTIVO MOVIMIENTO': motivo_actual,  # se normaliza luego
                    'FECHA_OPER': fecha_oper,
                    'SUCURSAL': sucursal,
                    'RECIBO': recibo,
                    'BULTOS': bultos,
                    "MONEDA": _normaliza_moneda_iso(moneda_actual),
                    'MONTO': importe,
                    'SALDO_ANTERIOR': saldo_anterior_hoja,
                })

    # DataFrame base
    df_out = pd.DataFrame(registros, columns=[
        'HOJA_ORIGEN', 'AGENCIA', 'FECHA_ARCHIVO', 'ING_EGR', 'CLASIFICACION',
        'MOTIVO MOVIMIENTO', 'FECHA_OPER', 'SUCURSAL',
        'RECIBO', 'BULTOS', 'MONEDA', 'MONTO', 'SALDO_ANTERIOR'
    ])

    if df_out.empty:
        # Creamos estructura vacía para no romper el flujo
        df_out = pd.DataFrame(columns=[
            'HOJA_ORIGEN', 'AGENCIA', 'FECHA_ARCHIVO', 'ING_EGR', 'CLASIFICACION',
            'MOTIVO MOVIMIENTO', 'FECHA_OPER', 'SUCURSAL',
            'RECIBO', 'BULTOS', 'MONEDA', 'MONTO', 'SALDO_ANTERIOR'
        ])
        logger.error(f'[EC_BANCO] {filename}: No se detectaron registros válidos.')

    # Normalizar encabezados y ordenar
    df_out = df_out.rename(columns={'MOTIVO MOVIMIENTO': 'MOTIVO_MOVIMIENTO'})
    df_out = _ordenar_y_renombrar_columnas_ec_banco(df_out)

    # Guardar
    df_out.to_excel(path_salida, index=False)
    logger.info(f'[EC_BANCO] Guardado: {path_salida}')
    return path_salida

def get_ec_bultos_atm(fecha_ejecucion: datetime,
                      filename: str,
                      dir_entrada: str,
                      dir_consolidado: str,
                      sheet_name: Union[int, str] = 0,
                      descartar_usd_cero: bool = True) -> Optional[str]:
    """
    Procesa 'EC_BULTOS_ATM*.xlsx' en formato LONG (una fila por moneda: PYG, USD).
    - Genera salida en dir_consolidado con sufijo '_PROCESADO.xlsx'
    - Si descartar_usd_cero=True, no genera fila USD cuando IMPORTE USD==0
    Devuelve la ruta de salida o None si no hubo registros.
    """
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    df_x = pd.read_excel(path_entrada, sheet_name=sheet_name, header=None, dtype=str).fillna('')

    rx_fecha_cell = re.compile(r'^\s*\d{1,2}/\d{1,2}/\d{4}\s*$')
    rx_totales = re.compile(r'\b(TOTAL|SUBTOTAL)\b', re.IGNORECASE)

    agencia = ''
    fecha_archivo = ''
    clasificacion = 'ATM'
    ing_egr = ''
    motivo_actual = ''

    registros: List[Dict[str, Any]] = []

    # Saldos anteriores (mismos para todas las filas de este archivo)
    saldo_ant_pyg = 0
    saldo_ant_usd = 0

    for _, row in df_x.iterrows():
        cells = [str(x) if x is not None else '' for x in row.values]
        strip_cells = [c.strip() for c in cells]
        line_join = ' '.join([c for c in strip_cells if c])
        if not line_join:
            continue

        upper_join = _strip_accents(line_join).upper()

        # Encabezados
        if 'PROSEGUR PARAGUAY S.A.' in upper_join:
            m = re.search(r'SUCURSAL:\s*([^)]+)\)', line_join, flags=re.IGNORECASE)
            if m:
                agencia = m.group(1).strip()
            continue

        if 'ESTADO DE CUENTA DE BULTOS DE ATM' in upper_join:
            m_f = re.search(r'AL:\s*(\d{1,2}/\d{1,2}/\d{4})', line_join, flags=re.IGNORECASE)
            if m_f:
                fecha_archivo = m_f.group(1)
            continue

        if upper_join == 'INGRESOS':
            ing_egr = 'IN'
            motivo_actual = ''
            continue

        if upper_join == 'EGRESOS':
            ing_egr = 'OUT'
            motivo_actual = ''
            continue

        if 'INFORME DE PROCESOS' in upper_join:
            # fin del bloque útil
            break

        if rx_totales.search(line_join):
            # ignorar líneas de totales/subtotales
            continue

        # SALDO ANTERIOR:
        # Orden típico en BULTOS_ATM: [cant_pyg, saldo_pyg, cant_usd, saldo_usd]
        if 'SALDO ANTERIOR' in upper_join and not (saldo_ant_pyg or saldo_ant_usd):
            vals = _extraer_saldos_desde_fila(strip_cells)
            if len(vals) >= 2:
                saldo_ant_pyg = vals[1] or 0
            if len(vals) >= 4:
                saldo_ant_usd = vals[3] or 0
            # No es fila de detalle
            continue

        # Buscar fecha en la fila
        date_idx = next((i for i, c in enumerate(strip_cells) if rx_fecha_cell.match(c)), None)

        # Si no hay fecha, puede ser MOTIVO
        if ing_egr and date_idx is None:
            motivo_actual = line_join.strip()
            continue

        # Fila de detalle (tiene fecha + hay ING/EG y motivo)
        if ing_egr and motivo_actual and date_idx is not None:
            fecha_oper = strip_cells[date_idx]

            # Sucursal
            suc_idx = _first_non_empty_after(strip_cells, date_idx)
            sucursal = _get_cell(strip_cells, suc_idx, default='')

            # Recibo
            rec_idx = _first_non_empty_after(strip_cells, suc_idx) if suc_idx is not None else None
            recibo_raw = _get_cell(strip_cells, rec_idx, default='')
            recibo_digits = _only_digits(recibo_raw)
            recibo = recibo_digits if recibo_digits != '' else recibo_raw

            # Bultos y montos por moneda: PYG primero, luego USD
            b_pyg_idx = _first_non_empty_after(strip_cells, rec_idx)
            bultos_pyg = _get_cell(strip_cells, b_pyg_idx, default='0') or '0'

            gua_idx = _first_non_empty_after(strip_cells, b_pyg_idx)
            guaranies = _get_cell(strip_cells, gua_idx, default='0') or '0'

            b_usd_idx = _first_non_empty_after(strip_cells, gua_idx)
            bultos_usd = _get_cell(strip_cells, b_usd_idx, default='0') or '0'

            usd_idx = _first_non_empty_after(strip_cells, b_usd_idx)
            dolares = _get_cell(strip_cells, usd_idx, default='0') or '0'

            # Fila PYG (se rellenan ambos saldos anteriores)
            registros.append({
                'FECHA_OPER': fecha_oper,
                'SUCURSAL': sucursal,
                'RECIBO': recibo,
                'BULTOS': bultos_pyg,
                'MONEDA': 'PYG',
                'IMPORTE': guaranies,
                'ING_EGR': ing_egr,
                'CLASIFICACION': clasificacion,
                'FECHA_ARCHIVO': fecha_archivo,
                'MOTIVO_MOVIMIENTO': motivo_actual,
                'AGENCIA': agencia,
                'SALDO_ANTERIOR_PYG': saldo_ant_pyg,
                'SALDO_ANTERIOR_USD': saldo_ant_usd,
            })

            # Fila USD (opcional si importe != 0)
            if not (descartar_usd_cero and _is_zero_like(dolares)):
                registros.append({
                    'FECHA_OPER': fecha_oper,
                    'SUCURSAL': sucursal,
                    'RECIBO': recibo,
                    'BULTOS': bultos_usd,
                    'MONEDA': 'USD',
                    'IMPORTE': dolares,
                    'ING_EGR': ing_egr,
                    'CLASIFICACION': clasificacion,
                    'FECHA_ARCHIVO': fecha_archivo,
                    'MOTIVO_MOVIMIENTO': motivo_actual,
                    'AGENCIA': agencia,
                    'SALDO_ANTERIOR_PYG': saldo_ant_pyg,
                    'SALDO_ANTERIOR_USD': saldo_ant_usd,
                })

    # DataFrame de salida
    df_out = pd.DataFrame(registros)
    if df_out.empty:
        df_out = pd.DataFrame(columns=[
            'FECHA_OPER', 'SUCURSAL', 'RECIBO', 'BULTOS', 'MONEDA', 'IMPORTE',
            'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
            'AGENCIA', 'SALDO_ANTERIOR_PYG', 'SALDO_ANTERIOR_USD'
        ])
        logger.error(f'[EC_BULTOS_ATM] {filename}: No se detectaron registros válidos.')

    # Ordenar/renombrar columnas según helper
    df_out = _ordenar_y_renombrar_columnas_bultos(df_out)

    # Normalizar código de moneda (por si en algún caso no vienen exactos)
    if 'MONEDA' in df_out.columns:
        df_out['MONEDA'] = df_out['MONEDA'].apply(_normaliza_moneda_iso)

    # Guardar
    df_out.to_excel(path_salida, index=False)
    logger.info(f'[EC_BULTOS_ATM] Guardado: {path_salida}')
    return path_salida


def get_ec_bultos_bco(fecha_ejecucion: datetime,
                       filename: str,
                       dir_entrada: str,
                       dir_consolidado: str,
                       sheet_name=None) -> Optional[str]:
    """
    Procesa archivos 'EC_BULTOS_BCO*.xlsx' / 'EC_BULTOS_BANCO*.xlsx' en formato LONG:
      FECHA, SUCURSAL, RECIBO, BULTOS, MONEDA(ISO), IMPORTE, ING_EGR, CLASIFICACION, FECHA_ARCHIVO,
      MOTIVO_MOVIMIENTO, AGENCIA, SALDO_ANTERIOR, HOJA_ORIGEN.
    - Detecta moneda por nombre de hoja, encabezados o en línea (prioridad en ese orden).
    - Clasificación por encabezado ('ESTADO DE CUENTA DE ...'), default 'BULTO BCO'.
    Devuelve ruta de salida o None si no hubo registros.
    """
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    # Cargar hojas (si sheet_name=None -> todas)
    if sheet_name is None:
        hojas = pd.read_excel(path_entrada, sheet_name=None, header=None, dtype=str)
    elif isinstance(sheet_name, (list, tuple)):
        hojas = pd.read_excel(path_entrada, sheet_name=list(sheet_name), header=None, dtype=str)
    else:
        df_one = pd.read_excel(path_entrada, sheet_name=sheet_name, header=None, dtype=str)
        hojas = {sheet_name: df_one}

    rx_fecha_linea = re.compile(r'^\s*(\d{1,2}/\d{1,2}/\d{4})\b')
    rx_totales = re.compile(r'\b(TOTAL|SUBTOTAL)\b', re.IGNORECASE)
    # Incluye símbolos: ₲, G$, US$, U$S, R$, €, $
    rx_moneda = re.compile(
        r'(GUARAN[IÍ]ES|D[ÓO]LARES|EUROS?|REALES?|PESOS?|PYG|GS|G\$|₲|USD|US\$|U\$S|R\$|BRL|EUR|ARS|€|\$)',
        re.IGNORECASE
    )

    mapa_clasif = {
        'BANCO': 'BCO',
        'ATM': 'ATM',
        'BULTOS DE BANCO': 'BULTO BCO',
        'BULTOS DE ATM': 'BULTO ATM',
    }

    registros: List[Dict[str, Any]] = []

    for nombre_hoja, df in hojas.items():
        df = df.fillna('')

        agencia = ''
        fecha_archivo = ''
        clasificacion = 'BULTO BCO'  # por defecto
        ing_egr = ''                 # IN/OUT
        motivo_actual = ''
        saldo_anterior_hoja = 0

        # Moneda por defecto: por nombre de hoja; si no, asumimos PYG
        moneda_actual = _normaliza_moneda_iso(nombre_hoja)

        for _, row in df.iterrows():
            # Valores crudos de la fila
            row_vals = [str(x) if x is not None else '' for x in row.values]
            parts_all = [v.strip() for v in row_vals if v.strip()]
            linea = ' '.join(parts_all)
            if not linea:
                continue

            linea_up = _strip_accents(linea).upper()

            # --- SALDO ANTERIOR por hoja ---
            if 'SALDO ANTERIOR' in linea_up and not saldo_anterior_hoja:
                valores = _extraer_saldos_desde_fila(row_vals)
                # Orden típico por hoja: [cant_bultos, saldo]; usamos el saldo
                if len(valores) >= 2:
                    saldo_anterior_hoja = valores[1] or 0
                elif len(valores) == 1:
                    saldo_anterior_hoja = valores[0] or 0
                # si viene 0,00 -> 0, lo maneja _to_int dentro de _extraer_saldos_desde_fila
                continue

            # Agencia
            if 'PROSEGUR PARAGUAY S.A.' in linea_up:
                m = re.search(r'SUCURSAL:\s*([^)]+)\)', linea, flags=re.IGNORECASE)
                if m:
                    agencia = m.group(1).strip()
                continue

            # Clasificación + fecha de archivo
            if 'ESTADO DE CUENTA DE' in linea_up:
                m_tipo = re.search(r'ESTADO DE CUENTA DE\s+(.*?)\s+AL[:\s]', linea, flags=re.IGNORECASE)
                if m_tipo:
                    texto = m_tipo.group(1).strip()
                    texto_norm = _strip_accents(texto).upper()
                    clasificacion = mapa_clasif.get(texto_norm, texto.strip()) or clasificacion
                m_f = re.search(r'AL[:\s]+(\d{1,2}/\d{1,2}/\d{4})', linea, flags=re.IGNORECASE)
                if m_f:
                    fecha_archivo = m_f.group(1)
                # si aparece moneda en el encabezado, usarla
                m_mon_enc = rx_moneda.search(linea)
                if m_mon_enc:
                    moneda_actual = _normaliza_moneda_iso(m_mon_enc.group(1))
                continue

            # Secciones IN/OUT
            if linea_up == 'INGRESOS':
                ing_egr = 'IN'
                motivo_actual = ''
                continue
            if linea_up == 'EGRESOS':
                ing_egr = 'OUT'
                motivo_actual = ''
                continue

            # Fin del bloque útil
            if 'INFORME DE PROCESOS' in linea_up:
                break

            # Saltar totales/subtotales
            if rx_totales.search(linea):
                continue

            # Si vemos token de MONEDA fuera de detalle (sin fecha al inicio), actualizamos contexto
            if rx_moneda.search(linea) and not rx_fecha_linea.match(linea):
                moneda_actual = _normaliza_moneda_iso(rx_moneda.search(linea).group(1))
                continue

            # Encabezado de MOTIVO (línea no-fecha dentro de IN/OUT)
            if ing_egr and not rx_fecha_linea.match(linea):
                motivo_actual = linea.strip()
                continue

            # Detalle (empieza con fecha)
            m_date = rx_fecha_linea.match(linea)
            if ing_egr and motivo_actual and m_date:
                parts = parts_all
                if not parts:
                    continue

                fecha_oper = parts[0]

                # Índice del recibo: primer número con >=6 dígitos
                idx_rec = next(
                    (i for i, p in enumerate(parts[1:], 1) if re.fullmatch(r'\d{6,}', _strip_accents(p))),
                    None
                )
                if idx_rec is None:
                    # muy conservador: si no hay recibo claro, no registramos
                    continue

                sucursal = ' '.join(parts[1:idx_rec]).strip()
                recibo = parts[idx_rec]
                bultos = parts[idx_rec + 1] if idx_rec + 1 < len(parts) else ''
                importe = parts[idx_rec + 2] if idx_rec + 2 < len(parts) else ''

                # Última chance: si en la misma línea aparece un token de moneda, usarlo
                m_mon_inline = rx_moneda.search(linea)
                if m_mon_inline:
                    moneda_actual = _normaliza_moneda_iso(m_mon_inline.group(1))

                registros.append({
                    'FECHA': fecha_oper,           # ya con nombre final
                    'SUCURSAL': sucursal,
                    'RECIBO': recibo,
                    'BULTOS': bultos,
                    'MONEDA': moneda_actual or 'PYG',
                    'IMPORTE': importe,
                    'ING_EGR': ing_egr,
                    'CLASIFICACION': clasificacion,
                    'FECHA_ARCHIVO': fecha_archivo,
                    'MOTIVO_MOVIMIENTO': motivo_actual,
                    'AGENCIA': agencia,
                    'SALDO_ANTERIOR': saldo_anterior_hoja,
                    'HOJA_ORIGEN': nombre_hoja,
                })

    # DataFrame base
    df_out = pd.DataFrame(registros, columns=[
        'FECHA', 'SUCURSAL', 'RECIBO', 'BULTOS', 'MONEDA', 'IMPORTE',
        'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
        'AGENCIA', 'SALDO_ANTERIOR', 'HOJA_ORIGEN'
    ])

    if df_out.empty:
        df_out = pd.DataFrame(columns=[
            'FECHA', 'SUCURSAL', 'RECIBO', 'BULTOS', 'MONEDA', 'IMPORTE',
            'ING_EGR', 'CLASIFICACION', 'FECHA_ARCHIVO', 'MOTIVO_MOVIMIENTO',
            'AGENCIA', 'SALDO_ANTERIOR', 'HOJA_ORIGEN'
        ])
        logger.error(f'[EC_BULTOS_BCO] {filename}: No se detectaron registros válidos.')

    # Orden final (re-usa helper de bultos para mantener consistencia)
    df_out = _ordenar_y_renombrar_columnas_bultos(df_out)

    # Normalizar código de moneda por si acaso
    if 'MONEDA' in df_out.columns:
        df_out['MONEDA'] = df_out['MONEDA'].apply(_normaliza_moneda_iso)

    # Guardar salida
    df_out.to_excel(path_salida, index=False)
    logger.info(f'[EC_BULTOS_BCO] Guardado: {path_salida}')
    return path_salida


def get_inv_atm(fecha_ejecucion: datetime,
                filename: str,
                dir_entrada: str,
                dir_consolidado: str,
                include_zeros: bool = True) -> Optional[str]:
    """
    Procesa un archivo 'INV_BILLETES_ATM*.xls[x]' y genera un Excel procesado en dir_consolidado.
    Columnas de salida:
      FECHA_INVENTARIO, DIVISA, AGENCIA, AGRUPACION_EFECTIVO, TIPO_VALOR,
      DENOMINACION, DEPOSITO, CJE_DEP, CANJE, MONEDA, IMPORTE_TOTAL
    """
    # ---- Config/tokens específicos de INV ATM ----
    AGRUP_TOKENS = ["TESORO ATM", "FAJOS ATM", "PICOS ATM"]
    TIPO_TOKENS  = ["BILLETES (LADRILLOS)", "BILLETES"]  # orden importa
    FIN_MONEDA_UP = "TOTAL DE LA MONEDA"
    STOP_ROW_TOKENS = {
        "SUB TOTAL", "SUBTOTAL", "TOTAL DEL DEPÓSITO", "TOTAL DEL DEPOSITO",
        "TOTAL DEPÓSITO", "TOTAL DEPOSITO"
    }
    DATE_RE    = re.compile(r"(\d{2}/\d{2}/\d{4})")
    AGENCIA_RE = re.compile(r"SUCURSAL:\s*([^)]+)\)", re.IGNORECASE)
    TITULO_RE  = re.compile(r"SALDO DE INVENTARIO DE BILLETES ATM AL", re.IGNORECASE)

    def normaliza_divisa_code(code_upper: str) -> str:
        return _normaliza_moneda_iso(code_upper)

    # ---- Paths ----
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    # ---- Helpers internos de INV ----
    def extrae_agencia_y_fecha(df: pd.DataFrame) -> Dict[str, str]:
        agencia, fecha = "", ""
        for _, row in df.iterrows():
            for cell in row:
                t = _txt(cell)
                if not agencia:
                    m = AGENCIA_RE.search(t)
                    if m:
                        agencia = m.group(1).strip()
                if not fecha and (TITULO_RE.search(t) or "SALDO DE INVENTARIO" in t.upper()):
                    m = DATE_RE.search(t)
                    if m:
                        fecha = m.group(1)
            if agencia and fecha:
                break
        if not fecha:
            for _, row in df.iterrows():
                for cell in row:
                    m = DATE_RE.search(_txt(cell))
                    if m:
                        fecha = m.group(1)
                        break
                if fecha:
                    break
        return {"AGENCIA": agencia, "FECHA_INVENTARIO": fecha}

    def capturar_codigo_total(row_text_upper: str) -> Optional[str]:
        m = re.search(r"TOTAL\s+DE\s+LA\s+MONEDA\s+([A-Z]{3})", row_text_upper, flags=re.IGNORECASE)
        return m.group(1).upper() if m else None

    def buscar_fin_y_codigo(df: pd.DataFrame) -> Tuple[int, Optional[str]]:
        row_end, code = len(df), None
        for i, row in df.iterrows():
            row_up = " | ".join(_upper(c) for c in row.tolist())
            if FIN_MONEDA_UP in row_up:
                row_end = i
                code = capturar_codigo_total(row_up)
                break
        return row_end, code

    def buscar_inicio_por_divisa(df: pd.DataFrame, row_end: int) -> Optional[int]:
        for i, row in df.iterrows():
            if i >= row_end:
                break
            ups = [_upper(c) for c in row.tolist() if _txt(c)]
            if "USD" in ups or "PYG" in ups:
                return i
        return None

    def buscar_inicio_fallback(df: pd.DataFrame, row_end: int) -> Optional[int]:
        for i, row in df.iterrows():
            if i >= row_end:
                break
            nums = [j for j, c in enumerate(row.tolist()) if _to_int(c) is not None]
            if not nums:
                continue
            denom_col = nums[0]
            left_up = " ".join(_upper(row.iloc[j]) for j in range(0, denom_col) if _txt(row.iloc[j]))
            if any(tok in left_up for tok in AGRUP_TOKENS):
                return i
        return None

    def localiza_bloque(df: pd.DataFrame) -> Dict[str, Any]:
        row_end, code_total = buscar_fin_y_codigo(df)
        row_start = buscar_inicio_por_divisa(df, row_end)
        if row_start is None:
            row_start = buscar_inicio_fallback(df, row_end)
        if row_start is None:
            raise ValueError("No se pudo determinar el inicio del bloque (no se encontró USD/PYG ni agrupación con denominación).")
        return {"row_start": row_start, "row_end": row_end, "moneda_codigo": code_total}

    def fila_es_total_o_subtotal(row) -> bool:
        up = " ".join(_upper(c) for c in row.tolist())
        return any(tok in up for tok in STOP_ROW_TOKENS) or FIN_MONEDA_UP in up

    def lista_numeros_con_indices(row) -> List[Tuple[int, int]]:
        out = []
        for j, c in enumerate(row.tolist()):
            v = _to_int(c)
            if v is not None:
                out.append((j, v))
        return out

    def siguiente_numero_a_la_derecha(row, desde_col: int) -> Tuple[int, int]:
        ncols = len(row)
        for j in range(desde_col + 1, ncols):
            v = _to_int(row.iloc[j])
            if v is not None:
                return j, v
        return ncols, 0

    def detectar_agrup_y_tipo(left_cells: List[str]) -> Tuple[Optional[str], Optional[str]]:
        left_up = " ".join(_upper(c) for c in left_cells if _txt(c))
        tipo = None
        for t in TIPO_TOKENS:
            if t in left_up:
                tipo = t
                break
        agrup = None
        for a in AGRUP_TOKENS:
            if a in left_up:
                agrup = a
                break
        return agrup, tipo

    def parsea_cuerpo(df: pd.DataFrame, row_start: int, row_end: int, default_code: Optional[str],
                      agencia: str, fecha: str) -> List[Dict[str, Any]]:
        registros: List[Dict[str, Any]] = []
        cur_divisa = normaliza_divisa_code(default_code or "")
        cur_agrup, cur_tipo = "", ""

        for i in range(row_start, row_end):
            row = df.iloc[i]
            if fila_es_total_o_subtotal(row):
                continue

            ups = [_upper(c) for c in row.tolist() if _txt(c)]
            if "USD" in ups:
                cur_divisa = "USD"
            elif "PYG" in ups:
                cur_divisa = "PYG"

            nums = lista_numeros_con_indices(row)
            if not nums:
                continue
            denom_col, denom_val = nums[0]

            left_cells = [row.iloc[j] for j in range(0, denom_col)]
            agrup, tipo = detectar_agrup_y_tipo(left_cells)
            if agrup:
                cur_agrup = agrup
            if tipo:
                cur_tipo = tipo

            # Tomar los 5 números siguientes (DEPOSITO,CJE_DEP,CANJE,MONEDA,IMPORTE_TOTAL)
            idx = denom_col
            vals = []
            for _ in range(5):
                idx, v = siguiente_numero_a_la_derecha(row, idx)
                vals.append(v)
            while len(vals) < 5:
                vals.append(0)

            reg = {
                "FECHA_INVENTARIO": fecha,
                "DIVISA": cur_divisa or "PYG",
                "AGENCIA": agencia,
                "AGRUPACION_EFECTIVO": cur_agrup,
                "TIPO_VALOR": cur_tipo,
                "DENOMINACION": denom_val,
                "DEPOSITO": vals[0] or 0,
                "CJE_DEP": vals[1] or 0,
                "CANJE": vals[2] or 0,
                "MONEDA": vals[3] or 0,
                "IMPORTE_TOTAL": vals[4] or 0,
            }
            if include_zeros or any([reg["DEPOSITO"], reg["CJE_DEP"], reg["CANJE"], reg["MONEDA"], reg["IMPORTE_TOTAL"]]):
                registros.append(reg)

        return registros

    # ---- Procesar el archivo (todas las hojas) ----
    try:
        xls = pd.ExcelFile(path_entrada, engine="openpyxl")
    except Exception as e:
        logger.error(f"[INV_ATM] {filename}: No se pudo abrir el archivo ({e}).")
        return None

    registros: List[Dict[str, Any]] = []
    for sheet in xls.sheet_names:
        try:
            df = pd.read_excel(path_entrada, sheet_name=sheet, header=None, dtype=object, engine="openpyxl").fillna("")
            meta = extrae_agencia_y_fecha(df)
            lim = localiza_bloque(df)
            registros.extend(
                parsea_cuerpo(df, lim["row_start"], lim["row_end"], lim.get("moneda_codigo"),
                              meta.get("AGENCIA", ""), meta.get("FECHA_INVENTARIO", ""))
            )
        except Exception as e:
            # si una hoja falla, continuamos con las demás
            logger.info(f"[INV_ATM] Hoja '{sheet}' omitida: {e}")
            continue

    if not registros:
        logger.error(f"[INV_ATM] {filename}: No se extrajeron filas.")
        # guardo estructura vacía para mantener el flujo
        cols = ["FECHA_INVENTARIO","DIVISA","AGENCIA","AGRUPACION_EFECTIVO","TIPO_VALOR",
                "DENOMINACION","DEPOSITO","CJE_DEP","CANJE","MONEDA","IMPORTE_TOTAL"]
        pd.DataFrame(columns=cols).to_excel(path_salida, index=False)
        logger.info(f'[INV_ATM] Guardado vacío: {path_salida}')
        return path_salida

    df_out = pd.DataFrame(registros)[[
    "FECHA_INVENTARIO","DIVISA","AGENCIA",
    "AGRUPACION_EFECTIVO","TIPO_VALOR",
    "DENOMINACION","DEPOSITO","CJE_DEP","CANJE","MONEDA","IMPORTE_TOTAL"
    ]]

    # Re-normalizar por si se coló algún "GUARANIES", "DOLARES", etc.
    df_out["DIVISA"] = df_out["DIVISA"].apply(_normaliza_moneda_iso)

    df_out.sort_values(by=[
        "FECHA_INVENTARIO","AGENCIA","DIVISA",
        "AGRUPACION_EFECTIVO","TIPO_VALOR","DENOMINACION"
    ], inplace=True)

    # ---- Guardar ----
    df_out.to_excel(path_salida, index=False)
    logger.info(f"[INV_ATM] {filename}: {len(registros)} filas extraídas.")
    return path_salida


def get_inv_bco(fecha_ejecucion: datetime,
                filename: str,
                dir_entrada: str,
                dir_consolidado: str,
                include_zeros: bool = True) -> Optional[str]:
    """
    Procesa un archivo 'INV_BILLETES_BANCO*.xls[x]' y genera un Excel procesado en dir_consolidado.
    Columnas de salida:
      FECHA_INVENTARIO, DIVISA, AGENCIA, AGRUPACION_EFECTIVO, TIPO_VALOR,
      DENOMINACION, DEPOSITO, CJE_DEP, CANJE, MONEDA, IMPORTE_TOTAL
    """
    # ---- Config/tokens específicos de INV BANCO ----
    AGRUP_TOKENS = ["TESORO EFECTIVO", "FAJOS EFECTIVOS", "PICOS EFECTIVO"]
    TIPO_TOKENS  = ["BILLETES (LADRILLOS)", "MONEDAS (BOLSAS)", "MONEDAS (PAQUETES)", "BILLETES", "MONEDAS"]
    FIN_MONEDA_UP = "TOTAL DE LA MONEDA"
    STOP_ROW_TOKENS = {
        "SUB TOTAL", "SUBTOTAL", "TOTAL DEL DEPÓSITO", "TOTAL DEL DEPOSITO",
        "TOTAL DEPÓSITO", "TOTAL DEPOSITO"
    }
    DATE_RE    = re.compile(r"(\d{2}/\d{2}/\d{4})")
    TITULO_RE  = re.compile(r"SALDOS?\s+DE\s+INVENTARIO\s+DE\s+BILLETES\s+AL", re.IGNORECASE)
    AGENCIA_RE = re.compile(r"SUCURSAL:\s*([^)]+)\)", re.IGNORECASE)

    def normaliza_divisa_code(code_upper: str) -> str:
        return _normaliza_moneda_iso(code_upper)

    # ---- Paths ----
    path_entrada = os.path.join(dir_entrada, filename)
    p = Path(path_entrada)
    stem_out = p.stem + '_PROCESADO'
    path_salida = os.path.join(dir_consolidado, f'{stem_out}.xlsx')

    # ---- Helpers internos de INV BANCO ----
    def extrae_agencia_y_fecha(df: pd.DataFrame) -> Dict[str, str]:
        agencia, fecha = "", ""
        for _, row in df.iterrows():
            for cell in row:
                t = _txt(cell)
                if not agencia:
                    m = AGENCIA_RE.search(t)
                    if m:
                        agencia = m.group(1).strip()
                if not fecha and (TITULO_RE.search(t) or "INVENTARIO" in t.upper()):
                    m = DATE_RE.search(t)
                    if m:
                        fecha = m.group(1)
            if agencia and fecha:
                break
        if not fecha:
            for _, row in df.iterrows():
                for cell in row:
                    m = DATE_RE.search(_txt(cell))
                    if m:
                        fecha = m.group(1); break
                if fecha: break
        return {"AGENCIA": agencia, "FECHA_INVENTARIO": fecha}

    def capturar_codigo_total(row_text_upper: str) -> Optional[str]:
        m = re.search(r"TOTAL\s+DE\s+LA\s+MONEDA\s+([A-Z]{3})", row_text_upper, flags=re.IGNORECASE)
        return m.group(1).upper() if m else None

    def buscar_fin_y_codigo(df: pd.DataFrame) -> Tuple[int, Optional[str]]:
        row_end, code = len(df), None
        for i, row in df.iterrows():
            row_up = " | ".join(_upper(c) for c in row.tolist())
            if FIN_MONEDA_UP in row_up:
                row_end = i
                code = capturar_codigo_total(row_up)
                break
        return row_end, code

    def buscar_inicio_por_divisa(df: pd.DataFrame, row_end: int) -> Optional[int]:
        for i, row in df.iterrows():
            if i >= row_end: break
            ups = [_upper(c) for c in row.tolist() if _txt(c)]
            if "USD" in ups or "PYG" in ups:
                return i
        return None

    def buscar_inicio_por_cabecera(df: pd.DataFrame, row_end: int) -> Optional[int]:
        for i, row in df.iterrows():
            row_up = " | ".join(_upper(c) for c in row.tolist())
            if ("DIVISA" in row_up and "DENOM" in row_up and "CJE/DEP" in row_up and "IMPORTE" in row_up):
                return i + 1
        return None

    def buscar_inicio_fallback(df: pd.DataFrame, row_end: int) -> Optional[int]:
        for i, row in df.iterrows():
            if i >= row_end: break
            nums = [j for j, c in enumerate(row.tolist()) if _to_int(c) is not None]
            if not nums: continue
            denom_col = nums[0]
            left_up = " ".join(_upper(row.iloc[j]) for j in range(0, denom_col) if _txt(row.iloc[j]))
            if any(tok in left_up for tok in AGRUP_TOKENS):
                return i
        return None

    def localiza_bloque(df: pd.DataFrame) -> Dict[str, Any]:
        row_end, code_total = buscar_fin_y_codigo(df)
        row_start = buscar_inicio_por_cabecera(df, row_end)
        if row_start is None:
            row_start = buscar_inicio_por_divisa(df, row_end)
        if row_start is None:
            row_start = buscar_inicio_fallback(df, row_end)
        if row_start is None:
            raise ValueError("No se pudo determinar el inicio del bloque (cabecera / USD-PYG / agrupación+denominación).")
        return {"row_start": row_start, "row_end": row_end, "moneda_codigo": code_total}

    def fila_es_total_o_subtotal(row) -> bool:
        up = " ".join(_upper(c) for c in row.tolist())
        return any(tok in up for tok in STOP_ROW_TOKENS) or FIN_MONEDA_UP in up

    def lista_numeros_con_indices(row) -> List[Tuple[int, int]]:
        out = []
        for j, c in enumerate(row.tolist()):
            v = _to_int(c)
            if v is not None:
                out.append((j, v))
        return out

    def siguiente_numero_a_la_derecha(row, desde_col: int) -> Tuple[int, int]:
        ncols = len(row)
        for j in range(desde_col + 1, ncols):
            v = _to_int(row.iloc[j])
            if v is not None:
                return j, v
        return ncols, 0

    def detectar_agrup_y_tipo(left_cells: List[str]) -> Tuple[Optional[str], Optional[str]]:
        left_up = " ".join(_upper(c) for c in left_cells if _txt(c))
        tipo = None
        for t in TIPO_TOKENS:
            if t in left_up:
                tipo = t; break
        agrup = None
        for a in AGRUP_TOKENS:
            if a in left_up:
                agrup = a; break
        return agrup, tipo

    def parsea_cuerpo(df: pd.DataFrame, row_start: int, row_end: int, default_code: Optional[str],
                      agencia: str, fecha: str) -> List[Dict[str, Any]]:
        registros: List[Dict[str, Any]] = []
        cur_divisa = normaliza_divisa_code(default_code or "")
        cur_agrup, cur_tipo = "", ""

        for i in range(row_start, row_end):
            row = df.iloc[i]
            if fila_es_total_o_subtotal(row):
                continue

            ups = [_upper(c) for c in row.tolist() if _txt(c)]
            if "USD" in ups:
                cur_divisa = normaliza_divisa_code("USD")
            elif "PYG" in ups:
                cur_divisa = normaliza_divisa_code("PYG")

            nums = lista_numeros_con_indices(row)
            if not nums:
                continue
            denom_col, denom_val = nums[0]

            left_cells = [row.iloc[j] for j in range(0, denom_col)]
            agrup, tipo = detectar_agrup_y_tipo(left_cells)
            if agrup: cur_agrup = agrup
            if tipo:  cur_tipo = tipo

            # Después de DENOM vienen 5 números: DEPOSITO, CJE_DEP, CANJE, MONEDA, IMPORTE_TOTAL
            idx = denom_col
            vals = []
            for _ in range(5):
                idx, v = siguiente_numero_a_la_derecha(row, idx)
                vals.append(v)
            while len(vals) < 5:
                vals.append(0)

            reg = {
                "FECHA_INVENTARIO": fecha,
                "DIVISA": cur_divisa or "PYG",
                "AGENCIA": agencia,
                "AGRUPACION_EFECTIVO": cur_agrup,
                "TIPO_VALOR": cur_tipo,
                "DENOMINACION": denom_val,
                "DEPOSITO": vals[0] or 0,
                "CJE_DEP": vals[1] or 0,
                "CANJE": vals[2] or 0,
                "MONEDA": vals[3] or 0,
                "IMPORTE_TOTAL": vals[4] or 0,
            }
            if include_zeros or any([reg["DEPOSITO"], reg["CJE_DEP"], reg["CANJE"], reg["MONEDA"], reg["IMPORTE_TOTAL"]]):
                registros.append(reg)

        return registros

    # ---- Procesar el archivo (todas las hojas) ----
    try:
        xls = pd.ExcelFile(path_entrada, engine="openpyxl")
    except Exception as e:
        logger.error(f"[INV_BCO] {filename}: No se pudo abrir el archivo ({e}).")
        return None

    registros: List[Dict[str, Any]] = []
    for sheet in xls.sheet_names:
        try:
            df = pd.read_excel(path_entrada, sheet_name=sheet, header=None, dtype=object, engine="openpyxl").fillna("")
            meta = extrae_agencia_y_fecha(df)
            lim = localiza_bloque(df)
            registros.extend(
                parsea_cuerpo(df, lim["row_start"], lim["row_end"], lim.get("moneda_codigo"),
                              meta.get("AGENCIA", ""), meta.get("FECHA_INVENTARIO", ""))
            )
        except Exception as e:
            logger.info(f"[INV_BCO] Hoja '{sheet}' omitida: {e}")
            continue

    # ---- Salida ----
    cols = ["FECHA_INVENTARIO","DIVISA","AGENCIA","AGRUPACION_EFECTIVO","TIPO_VALOR",
            "DENOMINACION","DEPOSITO","CJE_DEP","CANJE","MONEDA","IMPORTE_TOTAL"]

    if not registros:
        logger.info(f"[INV_BCO] {filename}: No se extrajeron filas.")
        pd.DataFrame(columns=cols).to_excel(path_salida, index=False)
        logger.info(f'[INV_BCO] Guardado vacío: {path_salida}')
        return path_salida

    df_out = pd.DataFrame(registros)[cols]
    # Normalizar DIVISA por si quedó algún texto tipo "GUARANIES", "DOLARES", etc.
    df_out["DIVISA"] = df_out["DIVISA"].apply(_normaliza_moneda_iso)

    df_out.sort_values(by=[
        "FECHA_INVENTARIO","AGENCIA","DIVISA","AGRUPACION_EFECTIVO","TIPO_VALOR","DENOMINACION"
    ], inplace=True)

    df_out.to_excel(path_salida, index=False)
    logger.info(f'[INV_BCO] Guardado: {path_salida}')
    return path_salida


# ==================== LÓGICA DE CARPETAS / ORQUESTACIÓN ====================

def resolve_root_prosegur() -> Path:
    """Devuelve la carpeta raíz de PROSEGUR.
    Asumimos que este script se ejecuta *dentro* de PROSEGUR.
    """
    return Path.cwd()

def colectar_pendientes(root: Path) -> List[Tuple[Path, str]]:
    """Busca archivos .xls/.xlsx en cada subcarpeta de agencia."""
    pendientes: List[Tuple[Path, str]] = []
    for ag in AGENCIAS:
        carpeta_ag = root / ag
        if not carpeta_ag.is_dir():
            continue
        for patron in ("*.xls", "*.xlsx"):
            for p in carpeta_ag.glob(patron):
                if p.name.startswith("~$"):  # archivos temporales de Excel
                    continue
                pendientes.append((p, ag))
    return pendientes

def obtener_dirs_salida(root: Path, agencia: str, fecha_str: str) -> Tuple[Path, Path]:
    """
    Devuelve (dir_procesado, dir_consolidado) para una agencia en la fecha indicada.
    Ambos son la MISMA carpeta:
        PROCESADO/AAAA-MM-DD/AGENCIA
    donde se guardan:
      - el archivo original (movido)
      - el archivo *_PROCESADO.*
    Eso se hace para poder verificar en caso de se necesite si el script 
    está capturando correctamente los datos o si hubo algún error
    """
    dir_trabajo = root / "PROCESADO" / fecha_str / agencia
    dir_trabajo.mkdir(parents=True, exist_ok=True)
    return dir_trabajo, dir_trabajo

def procesar_archivo(fecha_ejecucion: datetime, path: Path, agencia: str, root: Path) -> None:
    """
    Despacha según el prefijo del nombre y mueve el original a
    PROCESADO/AAAA-MM-DD/AGENCIA junto con el *_PROCESADO.
    """
    fecha_str = fecha_ejecucion.strftime("%Y-%m-%d")
    dir_entrada = str(path.parent)
    dir_procesado, dir_consolidado = obtener_dirs_salida(root, agencia, fecha_str)
    filename = path.name
    fname_upper = filename.upper()
    fname_norm = fname_upper.replace(" ", "_")

    try:
        salida: Optional[str] = None

        if fname_norm.startswith('EC_ATM'):
            salida = get_ec_atm(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        elif fname_norm.startswith('EC_BANCO') or fname_norm.startswith('EC_BCO'):
            salida = get_ec_banco(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        elif fname_norm.startswith('EC_BULTOS_ATM'):
            salida = get_ec_bultos_atm(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        elif fname_norm.startswith('EC_BULTOS_BCO') or fname_norm.startswith('EC_BULTOS_BANCO'):
            salida = get_ec_bultos_bco(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        elif fname_norm.startswith('INV_BILLETES_ATM') or fname_norm.startswith('INV_ATM'):
            salida = get_inv_atm(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        elif (fname_norm.startswith('INV_BILLETES_BANCO') or
              fname_norm.startswith('INV_BCO') or
              fname_norm.startswith('INV_BANCO')):
            salida = get_inv_bco(fecha_ejecucion, filename, dir_entrada, str(dir_consolidado))
        else:
            logger.info(f'[SKIP] No se reconoce tipo para: {filename}')
            return

        if salida is None:
            logger.info(f'[WARN] {filename}: parser no devolvió registros (salida=None). No se mueve el archivo.')
            return

        # Mover archivo original a PROCESADO/fecha/agencia
        dst = dir_procesado / filename
        shutil.move(str(path), str(dst))
        logger.info(f'[MOVE] {filename} -> {dst}')

    except Exception as e:
        logger.error(f'[ERROR] Procesando {filename}: {e}')



def generar_consolidados(root: Path, fecha_ejecucion: datetime) -> None:
    """
    Lee todos los *_PROCESADO.* de PROCESADO/AAAA-MM-DD/AGENCIA/
    y genera los consolidados finales en:

        CONSOLIDADO/AAAA-MM-DD/
            PROSEGUR_BULTOSATM.csv
            PROSEGUR_BULTOSBANCO.csv
            PROSEGUR_EFECTATM.csv
            PROSEGUR_EFECTBANCO.csv
            PROSEGUR_INVENTARIO_ATM.csv
            PROSEGUR_INVENTARIO_BCO.csv
    """
    fecha_str = fecha_ejecucion.strftime("%Y-%m-%d")
    base_proc = root / "PROCESADO" / fecha_str
    consol_dir = root / "CONSOLIDADO" / fecha_str
    consol_dir.mkdir(parents=True, exist_ok=True)

    if not base_proc.exists():
        logger.info(f"[CONSOLIDADO] No existe la carpeta {base_proc}, no se generan consolidados.")
        return

    # Acumuladores por tipo
    data = {
        "EFECT_ATM": [],
        "EFECT_BCO": [],
        "BULTOS_ATM": [],
        "BULTOS_BCO": [],
        "INV_ATM": [],
        "INV_BCO": [],
    }

    # Recorremos PROCESADO/fecha/AGENCIA y juntamos todos los *_PROCESADO
    for ag in AGENCIAS:
        ag_dir = base_proc / ag
        if not ag_dir.exists():
            continue

        # leemos todos los xlsx/csv procesados
        for pattern in ("*.xlsx", "*.csv"):
            for f in ag_dir.glob(pattern):
                fname_up = f.name.upper()
                # Sólo archivos procesados
                if "_PROCESADO" not in fname_up:
                    continue

                try:
                    if f.suffix.lower() == ".xlsx":
                        df = pd.read_excel(f)
                    else:
                        df = pd.read_csv(f)
                except Exception as e:
                    logger.info(f"[CONSOLIDADO] No se pudo leer '{f}': {e}")
                    continue

                # Clasificación por tipo según nombre
                if "EC_ATM" in fname_up:
                    data["EFECT_ATM"].append(df)
                elif "EC_BANCO" in fname_up or "EC_BCO" in fname_up:
                    data["EFECT_BCO"].append(df)
                elif "EC_BULTOS_ATM" in fname_up:
                    data["BULTOS_ATM"].append(df)
                elif "EC_BULTOS_BCO" in fname_up or "EC_BULTOS_BANCO" in fname_up:
                    data["BULTOS_BCO"].append(df)
                elif "INV_BILLETES_ATM" in fname_up or "INV_ATM" in fname_up:
                    data["INV_ATM"].append(df)
                elif ("INV_BILLETES_BANCO" in fname_up or
                      "INV_BCO" in fname_up or
                      "INV_BANCO" in fname_up):
                    data["INV_BCO"].append(df)

    # === EFECTIVO ATM ===
    if data["EFECT_ATM"]:
        df_efect_atm = pd.concat(data["EFECT_ATM"], ignore_index=True)

        # Normalizar agencia
        if "AGENCIA" in df_efect_atm.columns:
            df_efect_atm["AGENCIA"] = df_efect_atm["AGENCIA"].apply(_normaliza_agencia)

        # Si por error arrastramos HOJA_ORIGEN, la quitamos
        if "HOJA_ORIGEN" in df_efect_atm.columns:
            df_efect_atm = df_efect_atm.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_EFECTATM.csv"
        df_efect_atm.to_csv(out_path, index=False, encoding="utf-8-sig")
        logger.info(f"[CONSOLIDADO] PROSEGUR_EFECTATM.csv: {df_efect_atm.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_EFECTATM.csv")

    # === EFECTIVO BANCO ===
    if data["EFECT_BCO"]:
        df_efect_bco = pd.concat(data["EFECT_BCO"], ignore_index=True)

        if "AGENCIA" in df_efect_bco.columns:
            df_efect_bco["AGENCIA"] = df_efect_bco["AGENCIA"].apply(_normaliza_agencia)

        # Este sí suele llevar HOJA_ORIGEN, pero lo sacamos en el consolidado final
        if "HOJA_ORIGEN" in df_efect_bco.columns:
            df_efect_bco = df_efect_bco.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_EFECTBANCO.csv"
        df_efect_bco.to_csv(out_path, index=False, encoding="utf-8-sig")
        logger.info(f"[CONSOLIDADO] PROSEGUR_EFECTBANCO.csv: {df_efect_bco.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_EFECTBANCO.csv")

    # === BULTOS ATM ===
    # === BULTOS ATM ===
    if data["BULTOS_ATM"]:
        df_bultos_atm = pd.concat(data["BULTOS_ATM"], ignore_index=True)

        # Normalizar agencia
        if "AGENCIA" in df_bultos_atm.columns:
            df_bultos_atm["AGENCIA"] = df_bultos_atm["AGENCIA"].apply(_normaliza_agencia)

        # Normalizar moneda por si acaso
        if "MONEDA" in df_bultos_atm.columns:
            df_bultos_atm["MONEDA"] = df_bultos_atm["MONEDA"].apply(_normaliza_moneda_iso)

        # Construir una sola columna SALDO_ANTERIOR en función de MONEDA
        if "SALDO_ANTERIOR" not in df_bultos_atm.columns:
            df_bultos_atm["SALDO_ANTERIOR"] = 0

        if "SALDO_ANTERIOR_PYG" in df_bultos_atm.columns and "SALDO_ANTERIOR_USD" in df_bultos_atm.columns:
            # Para filas en PYG
            df_bultos_atm.loc[df_bultos_atm["MONEDA"] == "PYG", "SALDO_ANTERIOR"] = \
                df_bultos_atm.loc[df_bultos_atm["MONEDA"] == "PYG", "SALDO_ANTERIOR_PYG"]

            # Para filas en USD
            df_bultos_atm.loc[df_bultos_atm["MONEDA"] == "USD", "SALDO_ANTERIOR"] = \
                df_bultos_atm.loc[df_bultos_atm["MONEDA"] == "USD", "SALDO_ANTERIOR_USD"]

            # Ya no necesitamos las columnas separadas
            df_bultos_atm = df_bultos_atm.drop(columns=["SALDO_ANTERIOR_PYG", "SALDO_ANTERIOR_USD"])

        # No queremos HOJA_ORIGEN en el consolidado final
        if "HOJA_ORIGEN" in df_bultos_atm.columns:
            df_bultos_atm = df_bultos_atm.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_BULTOSATM.csv"
        df_bultos_atm.to_csv(out_path, index=False, encoding="utf-8-sig", sep=';')
        logger.info(f"[CONSOLIDADO] PROSEGUR_BULTOSATM.csv: {df_bultos_atm.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_BULTOSATM.csv")


    # === BULTOS BANCO ===
    if data["BULTOS_BCO"]:
        df_bultos_bco = pd.concat(data["BULTOS_BCO"], ignore_index=True)

        if "AGENCIA" in df_bultos_bco.columns:
            df_bultos_bco["AGENCIA"] = df_bultos_bco["AGENCIA"].apply(_normaliza_agencia)

        # Aquí también puede venir HOJA_ORIGEN y tampoco la queremos
        if "HOJA_ORIGEN" in df_bultos_bco.columns:
            df_bultos_bco = df_bultos_bco.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_BULTOSBANCO.csv"
        df_bultos_bco.to_csv(out_path, index=False, encoding="utf-8-sig")
        logger.info(f"[CONSOLIDADO] PROSEGUR_BULTOSBANCO.csv: {df_bultos_bco.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_BULTOSBANCO.csv")

    # === INVENTARIO ATM ===
    if data["INV_ATM"]:
        df_inv_atm = pd.concat(data["INV_ATM"], ignore_index=True)

        if "AGENCIA" in df_inv_atm.columns:
            df_inv_atm["AGENCIA"] = df_inv_atm["AGENCIA"].apply(_normaliza_agencia)

        if "HOJA_ORIGEN" in df_inv_atm.columns:
            df_inv_atm = df_inv_atm.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_INVENTARIO_ATM.csv"
        df_inv_atm.to_csv(out_path, index=False, encoding="utf-8-sig")
        logger.info(f"[CONSOLIDADO] PROSEGUR_INVENTARIO_ATM.csv: {df_inv_atm.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_INVENTARIO_ATM.csv")

    # === INVENTARIO BANCO ===
    if data["INV_BCO"]:
        df_inv_bco = pd.concat(data["INV_BCO"], ignore_index=True)

        if "AGENCIA" in df_inv_bco.columns:
            df_inv_bco["AGENCIA"] = df_inv_bco["AGENCIA"].apply(_normaliza_agencia)

        if "HOJA_ORIGEN" in df_inv_bco.columns:
            df_inv_bco = df_inv_bco.drop(columns=["HOJA_ORIGEN"])

        out_path = consol_dir / "PROSEGUR_INVENTARIO_BCO.csv"
        df_inv_bco.to_csv(out_path, index=False, encoding="utf-8-sig")
        logger.info(f"[CONSOLIDADO] PROSEGUR_INVENTARIO_BCO.csv: {df_inv_bco.shape[0]} filas -> {out_path}")
    else:
        logger.info("[CONSOLIDADO] No se encontraron datos para PROSEGUR_INVENTARIO_BCO.csv")


########################################
################ MAIN ##################
########################################

def main():
    root = resolve_root_prosegur()
    fecha_ejecucion = datetime.now()
    fecha_str = fecha_ejecucion.strftime("%Y-%m-%d")

    # Carpeta CONSOLIDADO/AAAA-MM-DD y log PROSEGUR.txt dentro
    consol_dir = root / "CONSOLIDADO" / fecha_str
    consol_dir.mkdir(parents=True, exist_ok=True)

    # Agregamos archivo de log para esta corrida
    logger.add(
        str(consol_dir / "PROSEGUR.txt"),
        level="INFO",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
    )

    logger.info("=" * 50)
    logger.info(f"[INICIO] Consolidado PROSEGUR unificado - {fecha_ejecucion:%Y-%m-%d %H:%M:%S}")
    logger.info(f"ROOT = {root}")

    pendientes = colectar_pendientes(root)
    if not pendientes:
        logger.info("No se encontraron archivos pendientes en subcarpetas de agencias.")
    else:
        logger.info(f"Archivos pendientes encontrados: {len(pendientes)}")
        for path, agencia in pendientes:
            logger.info(f"Procesando {path.name} (agencia {agencia})...")
            procesar_archivo(fecha_ejecucion, path, agencia, root)

    # Generar los consolidados finales en CONSOLIDADO/AAAA-MM-DD
    generar_consolidados(root, fecha_ejecucion)

    logger.info("[FIN] Consolidado PROSEGUR unificado")

if __name__ == "__main__":
    main()
